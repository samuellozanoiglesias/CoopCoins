{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA backend failed to initialize: Unable to use CUDA because of the following issues with CUDA components:\n",
      "Outdated CUDA installation found.\n",
      "Version JAX was built against: 12030\n",
      "Minimum supported: 12010\n",
      "Installed version: 12000\n",
      "The local installation version must be no lower than 12010.\n",
      "--------------------------------------------------\n",
      "Outdated cuBLAS installation found.\n",
      "Version JAX was built against: 120304\n",
      "Minimum supported: 120100\n",
      "Installed version: 120002\n",
      "The local installation version must be no lower than 120100.\n",
      "--------------------------------------------------\n",
      "Outdated cuSPARSE installation found.\n",
      "Version JAX was built against: 12200\n",
      "Minimum supported: 12100\n",
      "Installed version: 12001\n",
      "The local installation version must be no lower than 12100..(Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX is using: TFRT_CPU_0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jax #pip install jax\n",
    "#os.environ[\"JAX_PLATFORMS\"] = \"cpu\"  # Forces JAX to run on CPU\n",
    "print(f\"JAX is using: {jax.devices()[0]}\")\n",
    "import pickle\n",
    "import jaxmarl\n",
    "from jaxmarl.environments.switch_riddle import make_train\n",
    "from jaxmarl.viz.overcooked_visualizer import OvercookedVisualizer\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "from textwrap import dedent\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model parameters only\n",
    "def save_model(runner_state, save_dir, file):\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Construct the full file path\n",
    "    filename = os.path.join(save_dir, file)\n",
    "\n",
    "    # Extract train_state (first element of the tuple)\n",
    "    train_state_1 = runner_state[0]\n",
    "    train_state_2 = runner_state[1]\n",
    "\n",
    "    # Save only the model parameters\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump({'params_1': train_state_1.params, \n",
    "                     'params_2': train_state_2.params}, f)\n",
    "\n",
    "\n",
    "    print(f\"Model parameters saved to {filename}\")\n",
    "\n",
    "# Load the model parameters\n",
    "def load_model(load_dir, file):\n",
    "    filename = os.path.join(load_dir, file)\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"Model file {filename} not found.\")\n",
    "\n",
    "    with open(filename, \"rb\") as f:\n",
    "        saved_data = pickle.load(f)\n",
    "\n",
    "    # Ensure the loaded model has the correct parameter structure\n",
    "    if \"params_1\" not in saved_data or \"params_2\" not in saved_data:\n",
    "        raise ValueError(\"Invalid saved model file.\")\n",
    "\n",
    "    model_params_1 = saved_data[\"params_1\"]\n",
    "    model_params_2 = saved_data[\"params_2\"]\n",
    "    print(f\"Model parameters loaded from {filename}\")\n",
    "\n",
    "    return model_params_1, model_params_2\n",
    "\n",
    "def find_closest_checkpoint(fixed_step, load_dir):\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(load_dir)\n",
    "    \n",
    "    # Filter files that match the pattern 'trained_model_{step}.pkl'\n",
    "    checkpoint_files = [f for f in files if f.startswith(\"trained_model_\") and f.endswith(\".pkl\")]\n",
    "    \n",
    "    # Extract the step numbers from the filenames\n",
    "    steps = []\n",
    "    for file in checkpoint_files:\n",
    "        step_str = file.split('_')[-1].split('.')[0]  # Extract the step number\n",
    "        try:\n",
    "            step = int(step_str)\n",
    "            steps.append(step)\n",
    "        except ValueError:\n",
    "            continue  # Skip files that don't have a valid step number\n",
    "    \n",
    "    if len(steps) == 0:\n",
    "        raise FileNotFoundError(f\"No checkpoint files found in {load_dir}\")\n",
    "    \n",
    "    # Find the closest step to the fixed step\n",
    "    closest_step = min(steps, key=lambda x: abs(x - fixed_step))\n",
    "    closest_filename = f\"trained_model_{closest_step}.pkl\"\n",
    "    \n",
    "    print(f\"Found checkpoint: {closest_filename} for step {closest_step}\")\n",
    "    \n",
    "    # Load the model (assuming load_model function is available)\n",
    "    model_params_1, model_params_2 = load_model(load_dir, closest_filename)\n",
    "    \n",
    "    return model_params_1, model_params_2, closest_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_config(config):\n",
    "    \"\"\"Enhances config with additional computed parameters and prints it in a readable format.\"\"\"\n",
    "    env = jaxmarl.make(config[\"ENV_NAME\"], **config[\"ENV_KWARGS\"])\n",
    "\n",
    "    # Compute additional parameters\n",
    "    config[\"NUM_ACTORS\"] = env.num_agents * config[\"NUM_ENVS\"]\n",
    "    config[\"NUM_UPDATES\"] = int(config[\"TOTAL_TIMESTEPS\"] // config[\"NUM_STEPS\"] // config[\"NUM_ENVS\"])\n",
    "    config[\"NUM_SAVES\"] = int(config[\"NUM_UPDATES\"] // config[\"SAVE_EVERY_N_EPOCHS\"])\n",
    "    config[\"MINIBATCH_SIZE\"] = (\n",
    "        int(config[\"NUM_ACTORS\"] / 2) * config[\"NUM_STEPS\"] // config[\"NUM_MINIBATCHES\"]\n",
    "    )\n",
    "\n",
    "    # Print all configuration settings in a structured way\n",
    "    print(\"\\n===== CONFIGURATION SETTINGS =====\")\n",
    "    for key in sorted(config.keys()):  # Sort keys alphabetically for readability\n",
    "        print(f\"{key}: {config[key]}\")\n",
    "    print(\"==================================\\n\")\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved in /data/samuel_lozano/hfsp_collective_learning/data_switch_riddle/Asymmetric_Agents/Checkpoints_2025-05-29_18-08-54/configuration_2025-05-29_18-08-54.txt\n",
      "agent_0\n",
      "agent_1\n",
      "agent_2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Value 'agent_0' with type <class 'str'> is not a valid JAX type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 94\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUM_SEEDS\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     93\u001b[0m     train_jit \u001b[38;5;241m=\u001b[39m make_train(config)\n\u001b[0;32m---> 94\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_jit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrngs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData saved in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/hfsp_overcooked_mod/JaxMARL/jaxmarl/environments/switch_riddle/make_train.py:431\u001b[0m, in \u001b[0;36mmake_train.<locals>.train\u001b[0;34m(seed, rng, initial_dir, csv_file_path)\u001b[0m\n\u001b[1;32m    428\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minitial_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mSeed_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUM_UPDATES\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m--> 431\u001b[0m     runner_state, metric \u001b[38;5;241m=\u001b[39m \u001b[43m_update_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m save_intervals \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m step \u001b[38;5;241m==\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUM_UPDATES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    434\u001b[0m         save_model(runner_state, save_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m~/hfsp_overcooked_mod/JaxMARL/jaxmarl/environments/switch_riddle/make_train.py:390\u001b[0m, in \u001b[0;36mmake_train.<locals>.train.<locals>._update_step\u001b[0;34m(runner_state, unused)\u001b[0m\n\u001b[1;32m    388\u001b[0m loss_infos \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m update_state \u001b[38;5;129;01min\u001b[39;00m update_states:\n\u001b[0;32m--> 390\u001b[0m     update_state, loss_info \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscan_epoch_over_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUPDATE_EPOCHS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m     final_update_states\u001b[38;5;241m.\u001b[39mappend(update_state)\n\u001b[1;32m    394\u001b[0m     loss_infos\u001b[38;5;241m.\u001b[39mappend(loss_info)\n",
      "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
      "File \u001b[0;32m/data/samuel_lozano/anaconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/jax/_src/core.py:1455\u001b[0m, in \u001b[0;36mconcrete_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__jax_array__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete_aval(x\u001b[38;5;241m.\u001b[39m__jax_array__())\n\u001b[0;32m-> 1455\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid JAX \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1456\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Value 'agent_0' with type <class 'str'> is not a valid JAX type"
     ]
    }
   ],
   "source": [
    "cluster = \"cuenca\"\n",
    "\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "if cluster == \"cuenca\":\n",
    "    initial_dir = f'/data/samuel_lozano/hfsp_collective_learning/data_switch_riddle/Asymmetric_Agents/Checkpoints_{current_datetime}/'\n",
    "elif cluster == \"brigit\":\n",
    "    initial_dir = f'/mnt/lustre/home/samuloza/data/samuel_lozano/hfsp_collective_learning/data_switch_riddle/Asymmetric_Agents/Checkpoints_{current_datetime}/'\n",
    "else:\n",
    "    print(\"Introduce a valid cluster name\")\n",
    "\n",
    "# Save the original stdout reference (ONLY NOTEBOOKS)\n",
    "original_stdout = sys.stdout  \n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(initial_dir, exist_ok=True)\n",
    "\n",
    "# Define the output file name\n",
    "log_filename = f\"configuration_{current_datetime}.txt\"\n",
    "log_filepath = os.path.join(initial_dir, log_filename)\n",
    "\n",
    "# Redirect standard output to a file\n",
    "with open(log_filepath, \"w\") as log_file:\n",
    "    sys.stdout = log_file  # Redirect stdout to the file\n",
    "\n",
    "    print(f\"Timestamp: {current_datetime}\\n\")\n",
    "\n",
    "    # set hyperparameters:\n",
    "    config = {\n",
    "        # Number of possible actions in the environment. \n",
    "        \"NUM_ACTIONS\": 6, \n",
    "        # Controls how much the model updates its weights during optimization.\n",
    "        \"LR\": 1e-4, \n",
    "        # Number of parallel environments running simultaneously.\n",
    "        \"NUM_ENVS\": 8, \n",
    "        #Number of steps collected before running an update.\n",
    "        \"NUM_STEPS\": 1600, \n",
    "        # Total number of timesteps for training.\n",
    "        \"TOTAL_TIMESTEPS\": 1e7, \n",
    "        # Number of times each collected batch of experiences is used for gradient updates. More epochs allow for better learning from collected data but can lead to overfitting.\n",
    "        \"UPDATE_EPOCHS\": 4, \n",
    "        # Number of minibatches used during training updates. More minibatches reduce variance but increase computational cost.\n",
    "        \"NUM_MINIBATCHES\": 4, \n",
    "        # Discount factor for future rewards. A value close to 1 favors long-term rewards, while lower values prioritize immediate rewards.\n",
    "        \"GAMMA\": 0.99, \n",
    "        # Controls Generalized Advantage Estimation (GAE). Higher values lead to smoother, less biased advantage estimates.\n",
    "        \"GAE_LAMBDA\": 0.99, \n",
    "        # PPO-specific parameter that limits policy updates to prevent excessive changes. Lower values ensure stability but may slow training.\n",
    "        \"CLIP_EPS\": 0.2, \n",
    "        # Coefficient for entropy regularization, encouraging exploration. Higher values lead to more randomness in actions.\n",
    "        \"ENT_COEF\": 0.1, \n",
    "        # Coefficient for the value function loss. Higher values prioritize accurate value function learning.\n",
    "        \"VF_COEF\": 0.5, \n",
    "        # Limits the magnitude of gradients, preventing instability.\n",
    "        \"MAX_GRAD_NORM\": 0.5, \n",
    "        # Specifies the activation function for the network. Tanh helps with stable gradient flow but might limit expressiveness compared to ReLU.\n",
    "        \"ACTIVATION\": \"tanh\",\n",
    "        # The RL environment being used.\n",
    "        \"ENV_NAME\": \"switch_riddle\",\n",
    "        # Allows customization of environment settings, such as custom layouts.\n",
    "        \"ENV_KWARGS\": {\n",
    "        },\n",
    "        # If enabled, the learning rate decreases over time, improving stability in later training stages.\n",
    "        \"ANNEAL_LR\": True, \n",
    "        # Ensures reproducibility by fixing the random seed.\n",
    "        \"SEED\": 0,\n",
    "        # Runs multiple training instances with different seeds for robustness.\n",
    "        \"NUM_SEEDS\": 3,\n",
    "        # Saves model checkpoints every N epochs.\n",
    "        \"SAVE_EVERY_N_EPOCHS\": 50,\n",
    "    }\n",
    "    \n",
    "    config = make_config(config)\n",
    "\n",
    "    log_file.flush()\n",
    "\n",
    "# Restore standard output to the console\n",
    "sys.stdout = original_stdout\n",
    "\n",
    "print(f\"Configuration saved in {log_filepath}\")\n",
    "\n",
    "rng = jax.random.PRNGKey(config[\"SEED\"])\n",
    "rngs = jax.random.split(rng, config[\"NUM_SEEDS\"])\n",
    "csv_file_path = f'{initial_dir}mean_return_data_{current_datetime}.csv'\n",
    "os.makedirs(initial_dir, exist_ok=True)\n",
    "\n",
    "with open(csv_file_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"seed\", \"step\", \"mean_returns\"])\n",
    "\n",
    "# Training loop\n",
    "for seed in range(config[\"NUM_SEEDS\"]):\n",
    "    train_jit = make_train(config)\n",
    "    result = train_jit(seed, rngs[seed], initial_dir, csv_file_path)\n",
    "    print(f\"Data saved in {initial_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECREATING RESULTS OF TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD (WITHOUT CSV, WITH NPZ)\n",
    "\n",
    "def recreate_results(load_layout_name, load_datetime, show_figure=1):\n",
    "    original_dir = f'/data/samuel_lozano/hfsp_collective_learning/data_switch_riddle/Asymmetric_Agents/{load_layout_name}/Checkpoints_{load_datetime}/'\n",
    "    # Find all files matching the pattern \"plot_data_seed_{seed}.npz\"\n",
    "    seed_files = [f for f in os.listdir(original_dir) if re.match(r\"plot_data_seed_\\d+\\.npz\", f)]\n",
    "    seed_files.sort(key=lambda x: int(re.findall(r\"\\d+\", x)[0]))  # Sort by seed number\n",
    "\n",
    "    if not seed_files:\n",
    "        print(\"No seed files found!\")\n",
    "        return None, None, None\n",
    "    \n",
    "    max_steps_per_seed = {}\n",
    "    mean_returns_per_seed = [] \n",
    "\n",
    "    i = 0\n",
    "    for file in seed_files:\n",
    "        file_path = os.path.join(original_dir, file)\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        returns_list = jnp.expand_dims(data[\"returns\"], axis=0)\n",
    "        out_reconstructed = [{\"metrics\": {\"returned_episode_returns\": returns}} for returns in returns_list]\n",
    "    \n",
    "        returns = jnp.stack(out_reconstructed[0][\"metrics\"][\"returned_episode_returns\"])\n",
    "        mean_returns = returns.mean(axis=-1).reshape(-1)\n",
    "\n",
    "        mean_returns_per_seed.append(mean_returns)\n",
    "        \n",
    "        max_index = int(jnp.argmax(mean_returns))  # Index of max return\n",
    "        max_step = max_index / config[\"NUM_STEPS\"]  # Convert to update steps\n",
    "        max_value = float(mean_returns[max_index])  # Get max value\n",
    "        \n",
    "        max_steps_per_seed[f\"Seed {i}\"] = (max_step, max_value)\n",
    "\n",
    "        i += 1\n",
    "        \n",
    "    # Recreate the plot\n",
    "    if show_figure == 1:\n",
    "        plt.figure()\n",
    "        for i in range(len(seed_files)):\n",
    "            plt.plot(mean_returns_per_seed[i], label=f\"Seed {i}\")\n",
    "    \n",
    "        plt.xlabel(\"Update Step\")\n",
    "        plt.ylabel(\"Return\")\n",
    "        plt.legend()\n",
    "    \n",
    "        save_path = os.path.join(original_dir, f\"plot_{load_layout_name}_{load_datetime}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.show()\n",
    "\n",
    "    print(\"Max steps per seed (reconstructed):\")\n",
    "    print(max_steps_per_seed)\n",
    "    return mean_returns_per_seed, max_steps_per_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={}\n",
    "config[\"NUM_STEPS\"] = 1000\n",
    "\n",
    "# Directory containing the seed files\n",
    "load_datetime = '2025-03-22_14-11-41'\n",
    "\n",
    "# Run the function\n",
    "show_figure = 1\n",
    "mean_returns_per_seed, max_steps_per_seed = recreate_results(load_datetime, show_figure=show_figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_results_csv(cluster, load_datetime, show_figure=1):\n",
    "    if cluster == \"cuenca\":\n",
    "        original_dir = f'/data/samuel_lozano/hfsp_collective_learning/data_switch_riddle/Asymmetric_Agents/Checkpoints_{load_datetime}/'\n",
    "    elif cluster == \"brigit\":\n",
    "        original_dir = f'/mnt/lustre/home/samuloza/data/samuel_lozano/hfsp_collective_learning/data_switch_riddle/Asymmetric_Agents/Checkpoints_{load_datetime}/'\n",
    "    else:\n",
    "        print(\"Introduce a valid cluster name\")\n",
    "        return\n",
    "\n",
    "    data = pd.read_csv(f'{original_dir}mean_return_data_{load_datetime}.csv')\n",
    "    max_steps_per_seed = {}\n",
    "    mean_returns_per_seed = []\n",
    "\n",
    "    for seed in data['seed'].unique():\n",
    "        seed_data = data[data['seed'] == seed]\n",
    "        seed_data = seed_data.sort_values('step')\n",
    "        \n",
    "        mean_returns = seed_data['mean_returns'].apply(lambda x: float(x.strip('[]'))).to_numpy()\n",
    "        mean_returns_per_seed.append(mean_returns)\n",
    "\n",
    "        max_index = int(jnp.argmax(mean_returns))  # Index of max return\n",
    "        max_value = float(mean_returns[max_index])  # Get max value\n",
    "        \n",
    "        max_steps_per_seed[f\"Seed {seed}\"] = (max_index, max_value)\n",
    "    \n",
    "    if show_figure == 1:\n",
    "        plt.figure()\n",
    "        for seed_index in range(len(mean_returns_per_seed)):\n",
    "            steps = data[data['seed'] == seed_index]['step'].unique()  \n",
    "            plt.plot(steps, mean_returns_per_seed[seed_index], label=f'Seed {seed_index}')\n",
    "    \n",
    "        plt.xlabel('Update Step')\n",
    "        plt.ylabel('Mean Returns')\n",
    "        plt.ylim(-10, 175)\n",
    "        plt.legend() \n",
    "        \n",
    "        save_path = os.path.join(original_dir, f\"plot_{load_datetime}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.show()\n",
    "\n",
    "    print(\"Max steps per seed (reconstructed):\")\n",
    "    print(max_steps_per_seed)\n",
    "    return mean_returns_per_seed, max_steps_per_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAG2CAYAAACZEEfAAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQhxJREFUeJzt3XlYVnX+//HXjewBN6KyjaCQqZFpoom0UCaG2lim02TZhBuWozXplGWNGuY3l/bFcjajZlxaxqW0bFzCpdRyQbOUkjAsAR0NEBdE+Pz+6PL+dSci6A03HJ+P67qvi/uczznnfT7ecL8853POsRljjAAAACzKw90FAAAA1CXCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDS3hp21a9eqX79+ioyMlM1m0+LFi53m22y2Kl/PPPOMo03r1q3PmD99+vR63hMAANBQuTXsHD16VJ06ddKsWbOqnJ+fn+/0mjNnjmw2mwYOHOjUbsqUKU7tHnjggfooHwAANAKe7tx4nz591KdPn7PODw8Pd3q/ZMkS9ejRQ7GxsU7TAwMDz2gLAAAguTns1EZhYaGWLVumN99884x506dP11NPPaXo6GjdfffdGjt2rDw9z75rZWVlKisrc7yvrKzU4cOH1axZM9lstjqpHwAAuJYxRkeOHFFkZKQ8PM5+sqrRhJ0333xTgYGBGjBggNP0Bx98UPHx8QoJCdFnn32mCRMmKD8/X88///xZ1zVt2jSlp6fXdckAAKAe7Nu3Ty1btjzrfJsxxtRjPWdls9m0aNEi9e/fv8r57du3V69evfTKK69Uu545c+bovvvuU2lpqXx8fKps8+sjO8XFxYqOjta+ffsUFBR03vsAAADqT0lJiaKiolRUVCS73X7Wdo3iyM66deuUnZ2tt99++5xtExISdOrUKe3du1ft2rWrso2Pj0+VQSgoKIiwAwBAI3OuISiN4j47//znP9WlSxd16tTpnG2zsrLk4eGh0NDQeqgMAAA0dG49slNaWqo9e/Y43ufm5iorK0shISGKjo6W9PMhqnfffVfPPffcGctv2LBBmzZtUo8ePRQYGKgNGzZo7Nixuueee9S0adN62w8AANBwuTXsbN68WT169HC8HzdunCQpNTVVGRkZkqQFCxbIGKO77rrrjOV9fHy0YMECPfnkkyorK1NMTIzGjh3rWA8AAECDGaDsTiUlJbLb7SouLmbMDgDgDBUVFSovL3d3GRcdLy8vNWnS5Kzza/r93SgGKAMA4A7GGBUUFKioqMjdpVy0goODFR4efkH3wSPsAABwFqeDTmhoqPz9/bnxbD0yxujYsWM6cOCAJCkiIuK810XYAQCgChUVFY6g06xZM3eXc1Hy8/OTJB04cEChoaHVntKqTqO49BwAgPp2eoyOv7+/myu5uJ3u/wsZM0XYAQCgGpy6ci9X9D9hBwAAWBphBwAAuITNZtPixYvdXcYZCDsAAFjIwYMHNWrUKEVHR8vHx0fh4eFKSUnRp59+6u7SJEmzZs1S69at5evrq4SEBH3++ed1vk2uxgIAwEIGDhyokydP6s0331RsbKwKCwu1atUqHTp0yN2l6e2339a4ceM0e/ZsJSQk6MUXX1RKSoqys7Pr9JmWHNkBAMAiioqKtG7dOs2YMUM9evRQq1at1K1bN02YMEG33nqrU7sRI0aoRYsWCgoK0k033aTt27c7rWvJkiWKj4+Xr6+vYmNjlZ6erlOnTjnmf/vtt0pKSpKvr6/i4uK0YsWKc9b3/PPPKy0tTUOHDlVcXJxmz54tf39/zZkzx3WdUAWO7AAAUAPGGB0vr3DLtv28mtToqqSAgAAFBARo8eLF6t69u3x8fKpsd8cdd8jPz08fffSR7Ha7/vrXv6pnz5765ptvFBISonXr1unee+/Vyy+/rOuvv145OTkaOXKkJGny5MmqrKzUgAEDFBYWpk2bNqm4uFgPPfRQtbWdPHlSW7Zs0YQJExzTPDw8lJycrA0bNtS8M84DYQcAgBo4Xl6huEkfu2XbX09Jkb/3ub+yPT09lZGRobS0NM2ePVvx8fG64YYbNGjQIHXs2FGStH79en3++ec6cOCAIww9++yzWrx4sd577z2NHDlS6enpeuyxx5SamipJio2N1VNPPaXx48dr8uTJWrlypXbv3q2PP/5YkZGRkqSnn35affr0OWtt//vf/1RRUaGwsDCn6WFhYdq9e/d59UtNcRoLAAALGThwoPbv36/3339fvXv3VmZmpuLj45WRkSFJ2r59u0pLS9WsWTPHkaCAgADl5uYqJyfH0WbKlClO89PS0pSfn69jx45p165dioqKcgQdSUpMTHTH7tYIR3YAAKgBP68m+npKitu2XRu+vr7q1auXevXqpYkTJ2rEiBGaPHmyhgwZotLSUkVERCgzM/OM5YKDgyVJpaWlSk9P14ABA6pc9/lo3ry5mjRposLCQqfphYWFCg8PP6911hRhBwCAGrDZbDU6ldQQxcXFOe5/Ex8fr4KCAnl6eqp169ZVto+Pj1d2drbatGlT5fzLL79c+/btU35+vuMBnRs3bqy2Bm9vb3Xp0kWrVq1S//79JUmVlZVatWqVxowZc177VVON818NAACc4dChQ7rjjjs0bNgwdezYUYGBgdq8ebNmzpyp2267TZKUnJysxMRE9e/fXzNnzlTbtm21f/9+LVu2TLfffru6du2qSZMm6be//a2io6P1u9/9Th4eHtq+fbt27typqVOnKjk5WW3btlVqaqqeeeYZlZSU6IknnjhnfePGjVNqaqq6du2qbt266cUXX9TRo0c1dOjQOu0Xwg4AABYREBCghIQEvfDCC8rJyVF5ebmioqKUlpamxx9/XNLPR6g+/PBDPfHEExo6dKgOHjyo8PBwJSUlOQYPp6SkaOnSpZoyZYpmzJghLy8vtW/fXiNGjJD081VUixYt0vDhw9WtWze1bt1aL7/8snr37l1tfXfeeacOHjyoSZMmqaCgQFdddZWWL19+xqBlV7MZY0ydbqERKCkpkd1uV3FxsYKCgtxdDgCgAThx4oRyc3MVExNz3uNUcOGq+3eo6fc3V2MBAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAACXsNlsjgeONiSEHQAALOTgwYMaNWqUoqOj5ePjo/DwcKWkpOjTTz91d2lau3at+vXrp8jIyHoNRjwIFAAACxk4cKBOnjypN998U7GxsSosLNSqVat06NAhd5emo0ePqlOnTho2bJgGDBhQb9vlyA4AABZRVFSkdevWacaMGerRo4datWqlbt26acKECbr11lud2o0YMUItWrRQUFCQbrrpJm3fvt1pXUuWLFF8fLx8fX0VGxur9PR0nTp1yjH/22+/VVJSknx9fRUXF6cVK1acs74+ffpo6tSpuv3221230zXAkR0AAGrCGKn8mHu27eUv2WznbBYQEKCAgAAtXrxY3bt3l4+PT5Xt7rjjDvn5+emjjz6S3W7XX//6V/Xs2VPffPONQkJCtG7dOt177716+eWXdf311ysnJ0cjR46UJE2ePFmVlZUaMGCAwsLCtGnTJhUXF+uhhx5y5R67FGEHAICaKD8mPR3pnm0/vl/yvuSczTw9PZWRkaG0tDTNnj1b8fHxuuGGGzRo0CB17NhRkrR+/Xp9/vnnOnDggCMMPfvss1q8eLHee+89jRw5Uunp6XrssceUmpoqSYqNjdVTTz2l8ePHa/LkyVq5cqV2796tjz/+WJGRP/fJ008/rT59+tRRB1wYTmMBAGAhAwcO1P79+/X++++rd+/eyszMVHx8vDIyMiRJ27dvV2lpqZo1a+Y4EhQQEKDc3Fzl5OQ42kyZMsVpflpamvLz83Xs2DHt2rVLUVFRjqAjSYmJie7Y3RrhyA4AADXh5f/zERZ3bbsWfH191atXL/Xq1UsTJ07UiBEjNHnyZA0ZMkSlpaWKiIhQZmbmGcsFBwdLkkpLS5Wenl7lIGJfX9/z2QO3IuwAAFATNluNTiU1RHFxcY7LvOPj41VQUCBPT0+1bt26yvbx8fHKzs5WmzZtqpx/+eWXa9++fcrPz1dERIQkaePGjXVRuksQdgAAsIhDhw7pjjvu0LBhw9SxY0cFBgZq8+bNmjlzpm677TZJUnJyshITE9W/f3/NnDlTbdu21f79+7Vs2TLdfvvt6tq1qyZNmqTf/va3io6O1u9+9zt5eHho+/bt2rlzp6ZOnark5GS1bdtWqampeuaZZ1RSUqInnnjinPWVlpZqz549jve5ubnKyspSSEiIoqOj66xfCDsAAFhEQECAEhIS9MILLygnJ0fl5eWKiopSWlqaHn/8cUk/3+X4ww8/1BNPPKGhQ4fq4MGDCg8PV1JSksLCwiRJKSkpWrp0qaZMmaIZM2bIy8tL7du314gRIyRJHh4eWrRokYYPH65u3bqpdevWevnll9W7d+9q69u8ebN69OjheD9u3DhJUmpqqmNMUV2wGWNMna29kSgpKZHdbldxcbGCgoLcXQ4AoAE4ceKEcnNzFRMT0yjHqVhFdf8ONf3+duvVWOe6bfSQIUNks9mcXr9OjYcPH9bgwYMVFBSk4OBgDR8+XKWlpfW4FwAAoCFza9g5fdvoWbNmnbVN7969lZ+f73jNnz/faf7gwYP11VdfacWKFVq6dKnWrl3ruPERAACAW8fs9OnT55w3IDr9ELOq7Nq1S8uXL9cXX3yhrl27SpJeeeUV9e3bV88++6zT9f8AAODi1OBvKpiZmanQ0FC1a9dOo0aNcnqQ2YYNGxQcHOwIOtLPo8w9PDy0adOms66zrKxMJSUlTi8AAGBNDTrs9O7dW2+99ZZWrVqlGTNmaM2aNerTp48qKiokSQUFBQoNDXVaxtPTUyEhISooKDjreqdNmya73e54RUVF1el+AAAA92nQl54PGjTI8fOVV16pjh076tJLL1VmZqZ69ux53uudMGGC43I36efR3AQeAACsqUEf2fm12NhYNW/e3HFDovDwcB04cMCpzalTp3T48OGzjvORfh4HFBQU5PQCAADW1KjCzg8//KBDhw45bk2dmJiooqIibdmyxdFm9erVqqysVEJCgrvKBAAADYhbT2NVd9vokJAQpaena+DAgQoPD1dOTo7Gjx+vNm3aKCUlRdLPz+bo3bu341H25eXlGjNmjAYNGsSVWAAAQJKbj+xs3rxZnTt3VufOnSX9fNvozp07a9KkSWrSpIl27NihW2+9VW3bttXw4cPVpUsXrVu3Tj4+Po51zJ07V+3bt1fPnj3Vt29fXXfddfrb3/7mrl0CAOCiVdUNghsCtx7ZufHGG1Xd0yo+/vjjc64jJCRE8+bNc2VZAAA0WgcPHtSkSZO0bNkyFRYWqmnTpurUqZMmTZqka6+91q21TZs2TQsXLtTu3bvl5+ena665RjNmzFC7du3qdLsN+mosAABQOwMHDtTJkyf15ptvKjY2VoWFhVq1apXTfercZc2aNRo9erSuvvpqnTp1So8//rhuvvlmff3117rkkkvqbLuNaoAyAAA4u6KiIq1bt04zZsxQjx491KpVK3Xr1k0TJkzQrbfe6tRuxIgRatGihYKCgnTTTTdp+/btTutasmSJ4uPj5evrq9jYWKWnp+vUqVOO+d9++62SkpLk6+uruLg4rVix4pz1LV++XEOGDNEVV1yhTp06KSMjQ3l5eU4XGtUFjuwAAFADxhgdP3XcLdv28/STzWY7Z7uAgAAFBARo8eLF6t69u9MY11+644475Ofnp48++kh2u11//etf1bNnT33zzTcKCQnRunXrdO+99+rll1/W9ddfr5ycHMdzJydPnqzKykoNGDBAYWFh2rRpk4qLi/XQQw/Ver+Ki4sl/TwkpS7ZTHWDZi4SNX1EPADg4nHixAnl5uYqJiZGvr6+OlZ+TAnz3HNbk013b5K/l3+N2v7nP/9RWlqajh8/rvj4eN1www0aNGiQOnbsKElav369brnlFh04cMApDLVp00bjx4/XyJEjlZycrJ49e2rChAmO+f/+9781fvx47d+/X//97391yy236Pvvv3dc/bx8+XL16dNHixYtUv/+/c9ZZ2VlpW699VYVFRVp/fr1Z23363+HX6rp9zensQAAsJCBAwdq//79ev/999W7d29lZmYqPj5eGRkZkqTt27ertLRUzZo1cxwJCggIUG5urnJychxtpkyZ4jQ/LS1N+fn5OnbsmHbt2qWoqCin27wkJibWqs7Ro0dr586dWrBggcv2/Ww4jQUAQA34efpp091nf8h0XW+7Nnx9fdWrVy/16tVLEydO1IgRIzR58mQNGTJEpaWlioiIUGZm5hnLBQcHS/r5Pnjp6ekaMGBAleu+UGPGjNHSpUu1du1atWzZ8oLXdy6EHQAAasBms9X4VFJDExcX57j/TXx8vAoKCuTp6anWrVtX2T4+Pl7Z2dlq06ZNlfMvv/xy7du3T/n5+Y6nGmzcuPGcdRhj9MADD2jRokXKzMxUTEzMee1PbRF2AACwiEOHDumOO+7QsGHD1LFjRwUGBmrz5s2aOXOmbrvtNklScnKyEhMT1b9/f82cOVNt27bV/v37tWzZMt1+++3q2rWrJk2apN/+9reKjo7W7373O3l4eGj79u3auXOnpk6dquTkZLVt21apqal65plnVFJSoieeeOKc9Y0ePVrz5s3TkiVLFBgYqIKCAkmS3W6Xn1/tjl7VBmN2AACwiICAACUkJOiFF15QUlKSOnTooIkTJyotLU2vvvqqpJ+PUH344YdKSkrS0KFD1bZtWw0aNEjff/+9wsLCJEkpKSlaunSp/vvf/+rqq69W9+7d9cILL6hVq1aSJA8PDy1atEjHjx9Xt27dNGLECP3f//3fOet7/fXXVVxcrBtvvFERERGO19tvv113nSKuxpLE1VgAgDNVdxUQ6g9XYwEAAJwDYQcAAFgaYQcAAFgaYQcAAFgaYQcAgGpwHY97uaL/CTsAAFTBy8tLknTs2DE3V3JxO93/p/89zgc3FQQAoApNmjRRcHCwDhw4IEny9/ev0ZPH4RrGGB07dkwHDhxQcHCwmjRpct7rIuwAAHAW4eHhkuQIPKh/wcHBjn+H80XYAQDgLGw2myIiIhQaGqry8nJ3l3PR8fLyuqAjOqcRdgAAOIcmTZq45EsX7sEAZQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGluDTtr165Vv379FBkZKZvNpsWLFzvmlZeX69FHH9WVV16pSy65RJGRkbr33nu1f/9+p3W0bt1aNpvN6TV9+vR63hMAANBQuTXsHD16VJ06ddKsWbPOmHfs2DFt3bpVEydO1NatW7Vw4UJlZ2fr1ltvPaPtlClTlJ+f73g98MAD9VE+AABoBDzdufE+ffqoT58+Vc6z2+1asWKF07RXX31V3bp1U15enqKjox3TAwMDFR4eXqe1AgCAxqlRjdkpLi6WzWZTcHCw0/Tp06erWbNm6ty5s5555hmdOnWq2vWUlZWppKTE6QUAAKzJrUd2auPEiRN69NFHdddddykoKMgx/cEHH1R8fLxCQkL02WefacKECcrPz9fzzz9/1nVNmzZN6enp9VE2AABwM5sxxri7CEmy2WxatGiR+vfvf8a88vJyDRw4UD/88IMyMzOdws6vzZkzR/fdd59KS0vl4+NTZZuysjKVlZU53peUlCgqKkrFxcXVrhsAADQcJSUlstvt5/z+bvBHdsrLy/X73/9e33//vVavXn3OMJKQkKBTp05p7969ateuXZVtfHx8zhqEAACAtTTosHM66Hz77bf65JNP1KxZs3Muk5WVJQ8PD4WGhtZDhQAAoKFza9gpLS3Vnj17HO9zc3OVlZWlkJAQRURE6He/+522bt2qpUuXqqKiQgUFBZKkkJAQeXt7a8OGDdq0aZN69OihwMBAbdiwQWPHjtU999yjpk2bumu3AABAA+LWMTuZmZnq0aPHGdNTU1P15JNPKiYmpsrlPvnkE914443aunWr/vjHP2r37t0qKytTTEyM/vCHP2jcuHG1Ok1V03N+AACg4ajp93eDGaDsToQdAAAan5p+fzeq++wAAADUFmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYWq3DztatW/Xll1863i9ZskT9+/fX448/rpMnT7q0OAAAgAtV67Bz33336ZtvvpEkfffddxo0aJD8/f317rvvavz48S4vEAAA4ELUOux88803uuqqqyRJ7777rpKSkjRv3jxlZGToP//5j6vrAwAAuCC1DjvGGFVWVkqSVq5cqb59+0qSoqKi9L///c+11QEAAFygWoedrl27aurUqfrXv/6lNWvW6JZbbpEk5ebmKiwszOUFAgAAXIhah50XX3xRW7du1ZgxY/TEE0+oTZs2kqT33ntP11xzjcsLBAAAuBA2Y4xxxYpOnDihJk2ayMvLyxWrq1clJSWy2+0qLi5WUFCQu8sBAAA1UNPv7/O+z87Jkyf1ww8/KC8vT3l5eTpw4IDy8/NrtY61a9eqX79+ioyMlM1m0+LFi53mG2M0adIkRUREyM/PT8nJyfr222+d2hw+fFiDBw9WUFCQgoODNXz4cJWWlp7vbgEAAIs5r6uxrr/+evn5+alVq1aKiYlRTEyMWrdurZiYmFqt6+jRo+rUqZNmzZpV5fyZM2fq5Zdf1uzZs7Vp0yZdcsklSklJ0YkTJxxtBg8erK+++korVqzQ0qVLtXbtWo0cObK2uwUAACyq1qexrr32Wnl6euqxxx5TRESEbDab0/xOnTqdXyE2mxYtWqT+/ftL+vmoTmRkpP785z/r4YcfliQVFxcrLCxMGRkZGjRokHbt2qW4uDh98cUX6tq1qyRp+fLl6tu3r3744QdFRkbWaNucxgIAoPGp6fe3Z21XnJWVpS1btqh9+/YXVOC55ObmqqCgQMnJyY5pdrtdCQkJ2rBhgwYNGqQNGzYoODjYEXQkKTk5WR4eHtq0aZNuv/32KtddVlamsrIyx/uSkpK62xEAAOBWtT6NFRcXVy/30ykoKJCkMy5nDwsLc8wrKChQaGio03xPT0+FhIQ42lRl2rRpstvtjldUVJSLqwcAAA1FrcPOjBkzNH78eGVmZurQoUMqKSlxejUGEyZMUHFxseO1b98+d5cEAADqSK1PY50+rdSzZ0+n6cYY2Ww2VVRUuKSw8PBwSVJhYaEiIiIc0wsLCx2PqwgPD9eBAwecljt16pQOHz7sWL4qPj4+8vHxcUmdAACgYat12Pnkk0/qoo4zxMTEKDw8XKtWrXKEm5KSEm3atEmjRo2SJCUmJqqoqEhbtmxRly5dJEmrV69WZWWlEhIS6qVOAADQsNUq7JSXl2vKlCmaPXu2LrvssgveeGlpqfbs2eN4n5ubq6ysLIWEhCg6OloPPfSQpk6dqssuu0wxMTGaOHGiIiMjHVdsXX755erdu7fS0tI0e/ZslZeXa8yYMRo0aFCNr8QCAADWVquw4+XlpR07drhs45s3b1aPHj0c78eNGydJSk1NVUZGhsaPH6+jR49q5MiRKioq0nXXXafly5fL19fXsczcuXM1ZswY9ezZUx4eHho4cKBefvlll9UIAAAat1rfZ2fs2LHy8fHR9OnT66qmesd9dgAAaHzq7D47p06d0pw5c7Ry5Up16dJFl1xyidP8559/vvbVAgAA1JFah52dO3cqPj5e0s+PjvilX99NGQAAwN0a7NVYAAAArnDeTz0HAABoDGp9ZKdHjx7Vnq5avXr1BRUEAADgSrUOO6dv8HdaeXm5srKytHPnTqWmprqqLgAAAJeoddh54YUXqpz+5JNPqrS09IILAgAAcCWXjdm55557NGfOHFetDgAAwCVcFnY2bNjgdGdjAACAhqDWp7EGDBjg9N4Yo/z8fG3evFkTJ050WWEAAACuUOuwExQU5HQ1loeHh9q1a6cpU6bo5ptvdmlxAAAAF6rWYScjI6MOygAAAKgbtR6zExsbq0OHDp0xvaioSLGxsS4pCgAAwFVqHXb27t2rioqKM6aXlZXpxx9/dElRAAAArlLj01jvv/++4+ePP/5Ydrvd8b6iokKrVq1S69atXVocAADAhapx2Onfv7+kn59s/us7JXt5eal169Z67rnnXFocAADAhapx2KmsrJQkxcTE6IsvvlDz5s3rrCgAAABXqfXVWLm5uY6fT5w4wY0EAQBAg1brAcqVlZV66qmn9Jvf/EYBAQH67rvvJEkTJ07UP//5T5cXCAAAcCFqHXamTp2qjIwMzZw5U97e3o7pHTp00D/+8Q+XFgcAAHChah123nrrLf3tb3/T4MGD1aRJE8f0Tp06affu3S4tDgAA4ELVOuz8+OOPatOmzRnTKysrVV5e7pKiAAAAXKXWYScuLk7r1q07Y/p7772nzp07u6QoAAAAV6n11ViTJk1SamqqfvzxR1VWVmrhwoXKzs7WW2+9paVLl9ZFjQAAAOet1kd2brvtNn3wwQdauXKlLrnkEk2aNEm7du3SBx98oF69etVFjQAAAOfNZowxrlrZ5s2b1bVrV1etrt6UlJTIbreruLhYQUFB7i4HAADUQE2/v2t9ZKe0tFTHjx93mpaVlaV+/fopISGh9pUCAADUoRqHnX379ikxMVF2u112u13jxo3TsWPHdO+99yohIUGXXHKJPvvss7qsFQAAoNZqPED5kUce0YkTJ/TSSy9p4cKFeumll7Ru3TolJCQoJydHLVu2rMs6AQAAzkuNw87atWu1cOFCde/eXb///e8VHh6uwYMH66GHHqrD8gAAAC5MjU9jFRYWKiYmRpIUGhoqf39/9enTp84KAwAAcIVaDVD28PBw+vmXz8YCAABoiGp8GssYo7Zt28pms0n6+aqszp07OwUgSTp8+LBrKwQAALgANQ47b7zxRl3WAQAAUCdqHHZSU1Prsg4AAIA6UeubCgIAADQmhB0AAGBphB0AAGBphB0AAGBpDT7stG7dWjab7YzX6NGjJUk33njjGfPuv/9+N1cNAAAaihpfjXVaRUWFMjIytGrVKh04cECVlZVO81evXu2y4iTpiy++UEVFheP9zp071atXL91xxx2OaWlpaZoyZYrjvb+/v0trAAAAjVetw86f/vQnZWRk6JZbblGHDh0cNxmsKy1atHB6P336dF166aW64YYbHNP8/f0VHh5ep3UAAIDGqdZhZ8GCBXrnnXfUt2/fuqinWidPntS///1vjRs3zilkzZ07V//+978VHh6ufv36aeLEidUe3SkrK1NZWZnjfUlJSZ3WDQAA3KfWYcfb21tt2rSpi1rOafHixSoqKtKQIUMc0+6++261atVKkZGR2rFjhx599FFlZ2dr4cKFZ13PtGnTlJ6eXg8VAwAAd7MZY0xtFnjuuef03Xff6dVXX63zU1i/lpKSIm9vb33wwQdnbbN69Wr17NlTe/bs0aWXXlplm6qO7ERFRam4uFhBQUEurxsAALheSUmJ7Hb7Ob+/a31kZ/369frkk0/00Ucf6YorrpCXl5fT/OqOqFyI77//XitXrjzn+hMSEiSp2rDj4+MjHx8fl9cIAAAanlqHneDgYN1+++11UUu13njjDYWGhuqWW26ptl1WVpYkKSIioh6qAgAADV2tw447nn5eWVmpN954Q6mpqfL0/P8l5+TkaN68eerbt6+aNWumHTt2aOzYsUpKSlLHjh3rvU4AANDw1DrsuMPKlSuVl5enYcOGOU339vbWypUr9eKLL+ro0aOKiorSwIED9Ze//MVNlQIAgIam1gOUJem9997TO++8o7y8PJ08edJp3tatW11WXH2p6QAnAADQcNT0+7vWj4t4+eWXNXToUIWFhWnbtm3q1q2bmjVrpu+++059+vS5oKIBAABcrdZh57XXXtPf/vY3vfLKK/L29tb48eO1YsUKPfjggyouLq6LGgEAAM5brcNOXl6errnmGkmSn5+fjhw5Ikn6wx/+oPnz57u2OgAAgAtU67ATHh6uw4cPS5Kio6O1ceNGSVJubq7OY/gPAABAnap12Lnpppv0/vvvS5KGDh2qsWPHqlevXrrzzjvdcv8dAACA6tT6aqzKykpVVlY67nezYMECffbZZ7rssst03333ydvbu04KrUtcjQUAQONT0+/v87r03GoIOwAAND51dum5JK1bt0733HOPEhMT9eOPP0qS/vWvf2n9+vXnVy0AAEAdqXXY+c9//qOUlBT5+flp27ZtjqeHFxcX6+mnn3Z5gQAAABei1mFn6tSpmj17tv7+9787PfH82muvbZR3TwYAANZW67CTnZ2tpKSkM6bb7XYVFRW5oiYAAACXOa/77OzZs+eM6evXr1dsbKxLigIAAHCVWoedtLQ0/elPf9KmTZtks9m0f/9+zZ07Vw8//LBGjRpVFzUCAACcN8/aLvDYY4+psrJSPXv21LFjx5SUlCQfHx89/PDDeuCBB+qiRgAAgPN23vfZOXnypPbs2aPS0lLFxcUpICDA1bXVG+6zAwBA41PT7+9aH9k5zdvbW3Fxcee7OAAAQL2ocdgZNmxYjdrNmTPnvIsBAABwtRqHnYyMDLVq1UqdO3fm6eYAAKDRqHHYGTVqlObPn6/c3FwNHTpU99xzj0JCQuqyNgAAgAtW40vPZ82apfz8fI0fP14ffPCBoqKi9Pvf/14ff/wxR3oAAECDdd5XY33//ffKyMjQW2+9pVOnTumrr75qtFdkcTUWAACNT50+9VySPDw8ZLPZZIxRRUXF+a4GAACgTtUq7JSVlWn+/Pnq1auX2rZtqy+//FKvvvqq8vLyGu1RHQAAYG01HqD8xz/+UQsWLFBUVJSGDRum+fPnq3nz5nVZGwAAwAWr8ZgdDw8PRUdHq3PnzrLZbGdtt3DhQpcVV18YswMAQOPj8jso33vvvdWGHAAAgIaoVjcVBAAAaGzO+2osAACAxoCwAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALK1Bh50nn3xSNpvN6dW+fXvH/BMnTmj06NFq1qyZAgICNHDgQBUWFrqxYgAA0NA06LAjSVdccYXy8/Mdr/Xr1zvmjR07Vh988IHeffddrVmzRvv379eAAQPcWC0AAGhoPN1dwLl4enoqPDz8jOnFxcX65z//qXnz5ummm26SJL3xxhu6/PLLtXHjRnXv3r2+SwUAAA1Qgz+y8+233yoyMlKxsbEaPHiw8vLyJElbtmxReXm5kpOTHW3bt2+v6Ohobdiwodp1lpWVqaSkxOkFAACsqUGHnYSEBGVkZGj58uV6/fXXlZubq+uvv15HjhxRQUGBvL29FRwc7LRMWFiYCgoKql3vtGnTZLfbHa+oqKg63AsAAOBODfo0Vp8+fRw/d+zYUQkJCWrVqpXeeecd+fn5nfd6J0yYoHHjxjnel5SUEHgAALCoBn1k59eCg4PVtm1b7dmzR+Hh4Tp58qSKioqc2hQWFlY5xueXfHx8FBQU5PQCAADW1KjCTmlpqXJychQREaEuXbrIy8tLq1atcszPzs5WXl6eEhMT3VglAABoSBr0aayHH35Y/fr1U6tWrbR//35NnjxZTZo00V133SW73a7hw4dr3LhxCgkJUVBQkB544AElJiZyJRYAAHBo0GHnhx9+0F133aVDhw6pRYsWuu6667Rx40a1aNFCkvTCCy/Iw8NDAwcOVFlZmVJSUvTaa6+5uWoAANCQ2Iwxxt1FuFtJSYnsdruKi4sZvwMAQCNR0+/vRjVmBwAAoLYIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIadNiZNm2arr76agUGBio0NFT9+/dXdna2U5sbb7xRNpvN6XX//fe7qWIAANDQNOiws2bNGo0ePVobN27UihUrVF5erptvvllHjx51apeWlqb8/HzHa+bMmW6qGAAANDSe7i6gOsuXL3d6n5GRodDQUG3ZskVJSUmO6f7+/goPD6/v8gAAQCPQoI/s/FpxcbEkKSQkxGn63Llz1bx5c3Xo0EETJkzQsWPHql1PWVmZSkpKnF4AAMCaGvSRnV+qrKzUQw89pGuvvVYdOnRwTL/77rvVqlUrRUZGaseOHXr00UeVnZ2thQsXnnVd06ZNU3p6en2UDQAA3MxmjDHuLqImRo0apY8++kjr169Xy5Ytz9pu9erV6tmzp/bs2aNLL720yjZlZWUqKytzvC8pKVFUVJSKi4sVFBTk8toBAIDrlZSUyG63n/P7u1Ec2RkzZoyWLl2qtWvXVht0JCkhIUGSqg07Pj4+8vHxcXmdAACg4WnQYccYowceeECLFi1SZmamYmJizrlMVlaWJCkiIqKOqwMAAI1Bgw47o0eP1rx587RkyRIFBgaqoKBAkmS32+Xn56ecnBzNmzdPffv2VbNmzbRjxw6NHTtWSUlJ6tixo5urBwAADUGDHrNjs9mqnP7GG29oyJAh2rdvn+655x7t3LlTR48eVVRUlG6//Xb95S9/qdXYm5qe8wMAAA2HJcbsnCuHRUVFac2aNfVUDQAAaIwa1X12AAAAaouwAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALM0yYWfWrFlq3bq1fH19lZCQoM8//9zdJQEAgAbAEmHn7bff1rhx4zR58mRt3bpVnTp1UkpKig4cOODu0gAAgJvZjDHG3UVcqISEBF199dV69dVXJUmVlZWKiorSAw88oMcee+ycy5eUlMhut6u4uFhBQUEuq+vtFS/qWNkRl60PAIDG6rfXDleLppEuXWdNv789XbpVNzh58qS2bNmiCRMmOKZ5eHgoOTlZGzZsqHKZsrIylZWVOd6XlJTUSW0Z3/9DP3jZ6mTdAAA0Ju33Xe3ysFNTjT7s/O9//1NFRYXCwsKcpoeFhWn37t1VLjNt2jSlp6fXeW0RFQHyqzxW59sBAKChu8TXdWdOaqvRh53zMWHCBI0bN87xvqSkRFFRUS7fzpz7Nrp8nQAAoHYafdhp3ry5mjRposLCQqfphYWFCg8Pr3IZHx8f+fj41Ed5AADAzRr91Vje3t7q0qWLVq1a5ZhWWVmpVatWKTEx0Y2VAQCAhqDRH9mRpHHjxik1NVVdu3ZVt27d9OKLL+ro0aMaOnSou0sDAABuZomwc+edd+rgwYOaNGmSCgoKdNVVV2n58uVnDFoGAAAXH0vcZ+dC1dV9dgAAQN2p6fd3ox+zAwAAUB3CDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDRLPPX8Qp1+FmpJSYmbKwEAADV1+nv7XM80J+xIOnLkiCQpKirKzZUAAIDaOnLkiOx2+1nn28y54tBFoLKyUvv371dgYKBsNpvL1ltSUqKoqCjt27ev2kfPX6zon+rRP+dGH1WP/qke/VO9xtA/xhgdOXJEkZGR8vA4+8gcjuxI8vDwUMuWLets/UFBQQ32g9IQ0D/Vo3/OjT6qHv1TPfqneg29f6o7onMaA5QBAIClEXYAAIClEXbqkI+PjyZPniwfHx93l9Ig0T/Vo3/OjT6qHv1TPfqnelbqHwYoAwAAS+PIDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCTh2aNWuWWrduLV9fXyUkJOjzzz93d0ku9+STT8pmszm92rdv75h/4sQJjR49Ws2aNVNAQIAGDhyowsJCp3Xk5eXplltukb+/v0JDQ/XII4/o1KlTTm0yMzMVHx8vHx8ftWnTRhkZGfWxe7W2du1a9evXT5GRkbLZbFq8eLHTfGOMJk2apIiICPn5+Sk5OVnffvutU5vDhw9r8ODBCgoKUnBwsIYPH67S0lKnNjt27ND1118vX19fRUVFaebMmWfU8u6776p9+/by9fXVlVdeqQ8//NDl+1tb5+qfIUOGnPF56t27t1MbK/fPtGnTdPXVVyswMFChoaHq37+/srOzndrU5+9UQ/sbVpP+ufHGG8/4DN1///1ObazaP6+//ro6duzouAlgYmKiPvroI8f8i/mzI4M6sWDBAuPt7W3mzJljvvrqK5OWlmaCg4NNYWGhu0tzqcmTJ5srrrjC5OfnO14HDx50zL///vtNVFSUWbVqldm8ebPp3r27ueaaaxzzT506ZTp06GCSk5PNtm3bzIcffmiaN29uJkyY4Gjz3XffGX9/fzNu3Djz9ddfm1deecU0adLELF++vF73tSY+/PBD88QTT5iFCxcaSWbRokVO86dPn27sdrtZvHix2b59u7n11ltNTEyMOX78uKNN7969TadOnczGjRvNunXrTJs2bcxdd93lmF9cXGzCwsLM4MGDzc6dO838+fONn5+f+etf/+po8+mnn5omTZqYmTNnmq+//tr85S9/MV5eXubLL7+s8z6ozrn6JzU11fTu3dvp83T48GGnNlbun5SUFPPGG2+YnTt3mqysLNO3b18THR1tSktLHW3q63eqIf4Nq0n/3HDDDSYtLc3pM1RcXOyYb+X+ef/9982yZcvMN998Y7Kzs83jjz9uvLy8zM6dO40xF/dnh7BTR7p162ZGjx7teF9RUWEiIyPNtGnT3FiV602ePNl06tSpynlFRUXGy8vLvPvuu45pu3btMpLMhg0bjDE/f/l5eHiYgoICR5vXX3/dBAUFmbKyMmOMMePHjzdXXHGF07rvvPNOk5KS4uK9ca1ff5lXVlaa8PBw88wzzzimFRUVGR8fHzN//nxjjDFff/21kWS++OILR5uPPvrI2Gw28+OPPxpjjHnttddM06ZNHf1jjDGPPvqoadeuneP973//e3PLLbc41ZOQkGDuu+8+l+7jhThb2LntttvOuszF1D/GGHPgwAEjyaxZs8YYU7+/U43hb9iv+8eYn8POn/70p7MuczH1jzHGNG3a1PzjH/+46D87nMaqAydPntSWLVuUnJzsmObh4aHk5GRt2LDBjZXVjW+//VaRkZGKjY3V4MGDlZeXJ0nasmWLysvLnfqhffv2io6OdvTDhg0bdOWVVyosLMzRJiUlRSUlJfrqq68cbX65jtNtGltf5ubmqqCgwGlf7Ha7EhISnPojODhYXbt2dbRJTk6Wh4eHNm3a5GiTlJQkb29vR5uUlBRlZ2frp59+crRprH2WmZmp0NBQtWvXTqNGjdKhQ4cc8y62/ikuLpYkhYSESKq/36nG8jfs1/1z2ty5c9W8eXN16NBBEyZM0LFjxxzzLpb+qaio0IIFC3T06FElJiZe9J8dHgRaB/73v/+poqLC6QMjSWFhYdq9e7ebqqobCQkJysjIULt27ZSfn6/09HRdf/312rlzpwoKCuTt7a3g4GCnZcLCwlRQUCBJKigoqLKfTs+rrk1JSYmOHz8uPz+/Oto71zq9P1Xtyy/3NTQ01Gm+p6enQkJCnNrExMScsY7T85o2bXrWPju9joaqd+/eGjBggGJiYpSTk6PHH39cffr00YYNG9SkSZOLqn8qKyv10EMP6dprr1WHDh0kqd5+p3766acG/zesqv6RpLvvvlutWrVSZGSkduzYoUcffVTZ2dlauHChJOv3z5dffqnExESdOHFCAQEBWrRokeLi4pSVlXVRf3YIO7ggffr0cfzcsWNHJSQkqFWrVnrnnXcaTQhBwzFo0CDHz1deeaU6duyoSy+9VJmZmerZs6cbK6t/o0eP1s6dO7V+/Xp3l9Igna1/Ro4c6fj5yiuvVEREhHr27KmcnBxdeuml9V1mvWvXrp2ysrJUXFys9957T6mpqVqzZo27y3I7TmPVgebNm6tJkyZnjHIvLCxUeHi4m6qqH8HBwWrbtq327Nmj8PBwnTx5UkVFRU5tftkP4eHhVfbT6XnVtQkKCmpUger0/lT3uQgPD9eBAwec5p86dUqHDx92SZ81ts9fbGysmjdvrj179ki6ePpnzJgxWrp0qT755BO1bNnSMb2+fqca+t+ws/VPVRISEiTJ6TNk5f7x9vZWmzZt1KVLF02bNk2dOnXSSy+9dNF/dgg7dcDb21tdunTRqlWrHNMqKyu1atUqJSYmurGyuldaWqqcnBxFRESoS5cu8vLycuqH7Oxs5eXlOfohMTFRX375pdMX2IoVKxQUFKS4uDhHm1+u43SbxtaXMTExCg8Pd9qXkpISbdq0yak/ioqKtGXLFkeb1atXq7Ky0vFHOzExUWvXrlV5ebmjzYoVK9SuXTs1bdrU0cYKffbDDz/o0KFDioiIkGT9/jHGaMyYMVq0aJFWr159xum4+vqdaqh/w87VP1XJysqSJKfPkFX7pyqVlZUqKyu76D87XI1VRxYsWGB8fHxMRkaG+frrr83IkSNNcHCw0yh3K/jzn/9sMjMzTW5urvn0009NcnKyad68uTlw4IAx5udLHaOjo83q1avN5s2bTWJioklMTHQsf/pSx5tvvtlkZWWZ5cuXmxYtWlR5qeMjjzxidu3aZWbNmtVgLz0/cuSI2bZtm9m2bZuRZJ5//nmzbds28/333xtjfr70PDg42CxZssTs2LHD3HbbbVVeet65c2ezadMms379enPZZZc5XVpdVFRkwsLCzB/+8Aezc+dOs2DBAuPv73/GpdWenp7m2WefNbt27TKTJ09uEJdWV9c/R44cMQ8//LDZsGGDyc3NNStXrjTx8fHmsssuMydOnHCsw8r9M2rUKGO3201mZqbTpdPHjh1ztKmv36mG+DfsXP2zZ88eM2XKFLN582aTm5trlixZYmJjY01SUpJjHVbun8cee8ysWbPG5Obmmh07dpjHHnvM2Gw289///tcYc3F/dgg7deiVV14x0dHRxtvb23Tr1s1s3LjR3SW53J133mkiIiKMt7e3+c1vfmPuvPNOs2fPHsf848ePmz/+8Y+madOmxt/f39x+++0mPz/faR179+41ffr0MX5+fqZ58+bmz3/+sykvL3dq88knn5irrrrKeHt7m9jYWPPGG2/Ux+7V2ieffGIknfFKTU01xvx8+fnEiRNNWFiY8fHxMT179jTZ2dlO6zh06JC56667TEBAgAkKCjJDhw41R44ccWqzfft2c9111xkfHx/zm9/8xkyfPv2MWt555x3Ttm1b4+3tba644gqzbNmyOtvvmqquf44dO2Zuvvlm06JFC+Pl5WVatWpl0tLSzvgDaeX+qapvJDl93uvzd6qh/Q07V//k5eWZpKQkExISYnx8fEybNm3MI4884nSfHWOs2z/Dhg0zrVq1Mt7e3qZFixamZ8+ejqBjzMX92bEZY0z9HUcCAACoX4zZAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAdAg3XjjjXrooYfcXQYACyDsADgvZwsjGRkZCg4Orvd6MjMzZbPZznjQ4fnIzc3V3XffrcjISPn6+qply5a67bbbtHv3bknS3r17ZbPZHM9dAtCwebq7AABoSMrLy9WrVy+1a9dOCxcuVEREhH744Qd99NFHLglSAOofR3YA1KkhQ4aof//+Sk9PV4sWLRQUFKT7779fJ0+edLQ5evSo7r33XgUEBCgiIkLPPffcGev517/+pa5duyowMFDh4eG6++67HU9n3rt3r3r06CFJatq0qWw2m4YMGSLp5ycuT5s2TTExMfLz81OnTp303nvvnbXer776Sjk5OXrttdfUvXt3tWrVStdee62mTp2q7t27S5LjadudO3eWzWbTjTfe6Fj+H//4hy6//HL5+vqqffv2eu211xzzTh8RWrBgga655hr5+vqqQ4cOWrNmzfl1LoAaIewAqHOrVq3Srl27lJmZqfnz52vhwoVKT093zH/kkUe0Zs0aLVmyRP/973+VmZmprVu3Oq2jvLxcTz31lLZv367Fixdr7969jkATFRWl//znP5Kk7Oxs5efn66WXXpIkTZs2TW+99ZZmz56tr776SmPHjtU999xz1oDRokULeXh46L333lNFRUWVbT7//HNJ0sqVK5Wfn6+FCxdKkubOnatJkybp//7v/7Rr1y49/fTTmjhxot58802n5R955BH9+c9/1rZt25SYmKh+/frp0KFDtexVADXm1seQAmi0brjhBvOnP/3pjOlvvPGGsdvtjvepqakmJCTEHD161DHt9ddfNwEBAaaiosIcOXLEeHt7m3feeccx/9ChQ8bPz6/K9Z/2xRdfGEmOJ56ffqL6Tz/95Ghz4sQJ4+/vbz777DOnZYcPH27uuuuus6771VdfNf7+/iYwMND06NHDTJkyxeTk5Djm5+bmGklm27ZtTstdeumlZt68eU7TnnrqKZOYmOi03C+fwl5eXm5atmxpZsyYcdZ6AFwYjuwAqHOdOnWSv7+/431iYqJKS0u1b98+5eTk6OTJk0pISHDMDwkJUbt27ZzWsWXLFvXr10/R0dEKDAzUDTfcIEnKy8s763b37NmjY8eOqVevXgoICHC83nrrLeXk5Jx1udGjR6ugoEBz585VYmKi3n33XV1xxRVasWLFWZc5evSocnJyNHz4cKdtTZ069YxtJSYmOn729PRU165dtWvXrrOuG8CFYYAygPMSFBSk4uLiM6YXFRXJbre7dFtHjx5VSkqKUlJSNHfuXLVo0UJ5eXlKSUlxGvvza6WlpZKkZcuW6Te/+Y3TPB8fn2q3GRgYqH79+qlfv36aOnWqUlJSNHXqVPXq1avabf397393Cm6S1KRJk3PuI4C6w5EdAOelXbt2Z4yrkaStW7eqbdu2TtO2b9+u48ePO95v3LhRAQEBioqK0qWXXiovLy9t2rTJMf+nn37SN99843i/e/duHTp0SNOnT9f111+v9u3bOwYnn+bt7S1JTuNs4uLi5OPjo7y8PLVp08bpFRUVVeN9tdlsat++vY4ePXrWbYWFhSkyMlLffffdGds6PaD5l/t/2qlTp7RlyxZdfvnlNa4HQO1wZAfAeRk1apReffVVPfjggxoxYoR8fHy0bNkyzZ8/Xx988IFT25MnT2r48OH6y1/+or1792ry5MkaM2aMPDw8FBAQoOHDh+uRRx5Rs2bNFBoaqieeeEIeHv///2LR0dHy9vbWK6+8ovvvv187d+7UU0895bSNVq1ayWazaenSperbt6/8/PwUGBiohx9+WGPHjlVlZaWuu+46FRcX69NPP1VQUJBSU1PP2K+srCxNnjxZf/jDHxQXFydvb2+tWbNGc+bM0aOPPipJCg0NlZ+fn5YvX66WLVvK19dXdrtd6enpevDBB2W329W7d2+VlZVp8+bN+umnnzRu3DjHNmbNmqXLLrtMl19+uV544QX99NNPGjZsmCv/eQD8krsHDQFovD7//HPTq1cv06JFC2O3201CQoJZtGiRU5vU1FRz2223mUmTJplmzZqZgIAAk5aWZk6cOOFoc+TIEXPPPfcYf39/ExYWZmbOnHnGAOh58+aZ1q1bGx8fH5OYmGjef//9MwYJT5kyxYSHhxubzWZSU1ONMcZUVlaaF1980bRr1854eXmZFi1amJSUFLNmzZoq9+ngwYPmwQcfNB06dDABAQEmMDDQXHnllebZZ581FRUVjnZ///vfTVRUlPHw8DA33HCDY/rcuXPNVVddZby9vU3Tpk1NUlKSWbhwoTHm/w9QnjdvnunWrZvx9vY2cXFxZvXq1ef3DwCgRmzGGOPuwAXAuoYMGaKioiItXrzY3aW43d69exUTE6Nt27bpqquucnc5wEWDMTsAAMDSCDsAAMDSOI0FAAAsjSM7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0v4fbD+UHQuVlaMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max steps per seed (reconstructed):\n",
      "{'Seed 0': (0, 0.0), 'Seed 1': (0, 0.0), 'Seed 2': (0, 0.0)}\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the seed files\n",
    "cluster = \"brigit\"\n",
    "load_datetime = '2025-04-03_08-02-47'\n",
    "load_layout_name = 'custom_13'\n",
    "\n",
    "# Run the function\n",
    "show_figure = 1\n",
    "mean_returns_per_seed, max_steps_per_seed = recreate_results_csv(cluster, load_layout_name, load_datetime, show_figure=show_figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = int(3.15e3)\n",
    "\n",
    "plt.figure() \n",
    "for i in range(len(mean_returns_per_seed)):    \n",
    "    plt.plot(mean_returns_per_seed[i][:max_steps], label=f\"Seed {i}\")\n",
    "\n",
    "plt.xlabel(\"Update Step\")\n",
    "plt.ylabel(\"Return\")\n",
    "plt.ylim(-10, 195)\n",
    "plt.legend()\n",
    "\n",
    "if cluster == \"cuenca\":\n",
    "    original_dir = f'/data/samuel_lozano/hfsp_collective_learning/data_switch_riddle/Asymmetric_Agents/{load_layout_name}/Checkpoints_{load_datetime}/'\n",
    "elif cluster == \"brigit\":\n",
    "    original_dir = f'/mnt/lustre/home/samuloza/data/samuel_lozano/hfsp_collective_learning/data_switch_riddle/Asymmetric_Agents/{load_layout_name}/Checkpoints_{load_datetime}/'\n",
    "else:\n",
    "    print(\"Introduce a valid cluster name\")\n",
    "\n",
    "save_path = os.path.join(original_dir, f\"plot_zoom_{load_layout_name}_{load_datetime}.png\")\n",
    "plt.savefig(save_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_return_interval(seed, mean_returns_per_seed, config, searched_value, min_step, max_step):\n",
    "    for step in range(int(min_step), int(max_step + 1)):\n",
    "        scaled_step = step // config[\"NUM_STEPS\"]  # Adjust step according to NUM_STEPS\n",
    "        if mean_returns_per_seed[seed][step] == searched_value:\n",
    "            print(f\"First return value {searched_value} in seed {seed} at update_step: {step}. In update step: {scaled_step}\")\n",
    "            return scaled_step\n",
    "\n",
    "    print(f\"No return value {searched_value} found in seed {seed} within the specified range.\")\n",
    "    return None\n",
    "\n",
    "def find_different_value_return_interval(seed, mean_returns_per_seed, config, searched_value, min_step, max_step):\n",
    "    for step in range(int(min_step), int(max_step + 1)):\n",
    "        scaled_step = step // config[\"NUM_STEPS\"]  # Adjust step according to NUM_STEPS\n",
    "        if mean_returns_per_seed[seed][step] != searched_value:\n",
    "            print(f\"First return value {searched_value} in seed {seed} at update_step: {step}. In update step: {scaled_step}\")\n",
    "            return scaled_step\n",
    "\n",
    "    print(f\"No return value {searched_value} found in seed {seed} within the specified range.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2\n",
    "searched_value = 0\n",
    "min_step = 4e6\n",
    "max_step = 4.3e6\n",
    "\n",
    "found_step = find_value_return_interval(seed, mean_returns_per_seed, config, searched_value, min_step, max_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_steps(load_layout_name, load_datetime, mean_returns_per_seed, min_value, max_value, seed=None):\n",
    "    if cluster == \"cuenca\":\n",
    "        original_dir = f'/data/samuel_lozano/hfsp_collective_learning/data_switch_riddle/Asymmetric_Agents/{load_layout_name}/Checkpoints_{load_datetime}/'\n",
    "    elif cluster == \"brigit\":\n",
    "        original_dir = f'/mnt/lustre/home/samuloza/data/samuel_lozano/hfsp_collective_learning/data_switch_riddle/Asymmetric_Agents/{load_layout_name}/Checkpoints_{load_datetime}/'\n",
    "    else:\n",
    "        print(\"Introduce a valid cluster name\")\n",
    "        return\n",
    "\n",
    "    step_pattern = re.compile(r\"trained_model_(\\d+)\\.pkl\")\n",
    "\n",
    "    results = {}  # Final dictionary with the reconstructed values\n",
    "\n",
    "    seed_path = os.path.join(original_dir, f\"Seed_{seed}\")   \n",
    "    if os.path.isdir(seed_path):\n",
    "        steps = []\n",
    "        for file in os.listdir(seed_path):\n",
    "            step_match = step_pattern.match(file)\n",
    "            if step_match and min_value <= int(step_match.group(1)) and max_value >= int(step_match.group(1)):\n",
    "                steps.append(int(step_match.group(1)))\n",
    "\n",
    "        steps.sort()\n",
    "        for step in steps:                 \n",
    "            results[step] = mean_returns_per_seed[seed][step]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.0, 50: 0.0, 100: 0.0, 150: 0.0, 200: 0.0, 250: 0.0, 300: 0.0, 350: 0.0, 400: 0.0, 450: 0.0, 500: 0.0, 550: 0.0, 600: 0.0, 650: 0.0, 700: 0.0, 750: 0.0, 800: 0.0, 850: 0.0, 900: 0.0, 950: 0.0, 1000: 0.0, 1050: 0.0, 1100: 0.0, 1150: 0.0, 1200: 0.0, 1250: 0.0, 1300: 0.0, 1350: 0.0, 1400: 0.0, 1450: 0.0, 1500: 0.0, 1550: 0.0, 1600: 0.0, 1650: 0.0, 1700: 0.0, 1750: 0.0, 1800: 0.0, 1850: 0.0, 1900: 0.0, 1950: 0.0, 2000: 0.0, 2050: 0.0, 2100: 0.0, 2150: 0.0, 2200: 0.0, 2250: 0.0, 2300: 0.0, 2350: 0.0, 2400: 0.0, 2450: 0.0, 2500: 0.0, 2550: 0.0, 2600: 0.0, 2650: 0.0, 2700: 0.0, 2750: 0.0, 2800: 0.0, 2850: 0.0, 2900: 0.0, 2950: 0.0, 3000: 0.0, 3050: 0.0, 3100: 0.0, 3150: 0.0, 3200: 0.0, 3250: 0.0, 3300: 0.0, 3350: 0.0, 3400: 0.0, 3450: 0.0, 3500: 0.0, 3550: 0.0, 3600: 0.0, 3650: 0.0, 3700: 0.0, 3750: 0.0, 3800: 0.0, 3850: 0.0, 3900: 0.0, 3950: 0.0, 4000: 0.0, 4050: 0.0, 4100: 0.0, 4150: 0.0, 4200: 0.0, 4250: 0.0, 4300: 0.0, 4350: 0.0, 4400: 0.0, 4450: 0.0, 4500: 0.0, 4550: 0.0, 4600: 0.0, 4650: 0.0, 4700: 0.0, 4750: 0.0, 4800: 0.0, 4850: 0.0, 4900: 0.0, 4950: 0.0, 5000: 0.0, 5050: 0.0, 5100: 0.0, 5150: 0.0, 5200: 0.0, 5250: 0.0, 5300: 0.0, 5350: 0.0, 5400: 0.0, 5450: 0.0, 5500: 0.0, 5550: 0.0, 5600: 0.0, 5650: 0.0, 5700: 0.0, 5750: 0.0, 5800: 0.0, 5850: 0.0, 5900: 0.0, 5950: 0.0, 6000: 0.0, 6050: 0.0, 6100: 0.0, 6150: 0.0, 6200: 0.0, 6250: 0.0, 6300: 0.0, 6350: 0.0, 6400: 0.0, 6450: 0.0, 6500: 0.0, 6550: 0.0, 6600: 0.0, 6650: 0.0, 6700: 0.0, 6750: 0.0, 6800: 0.0, 6850: 0.0, 6900: 0.0, 6950: 0.0, 7000: 0.0, 7050: 0.0, 7100: 0.0, 7150: 0.0, 7200: 0.0, 7250: 0.0, 7300: 0.0, 7350: 0.0, 7400: 0.0, 7450: 0.0, 7500: 0.0, 7550: 0.0, 7600: 0.0, 7650: 0.0, 7700: 0.0, 7750: 0.0, 7800: 0.0, 7850: 0.0, 7900: 0.0, 7950: 0.0, 8000: 0.0, 8050: 0.0, 8100: 0.0, 8150: 0.0, 8200: 0.0, 8250: 0.0, 8300: 0.0, 8350: 0.0, 8400: 0.0, 8450: 0.0, 8500: 0.0, 8550: 0.0, 8600: 0.0, 8650: 0.0, 8700: 0.0, 8750: 0.0, 8800: 0.0, 8850: 0.0, 8900: 0.0, 8950: 0.0, 9000: 0.0, 9050: 0.0, 9100: 0.0, 9150: 0.0, 9200: 0.0, 9250: 0.0, 9300: 0.0, 9350: 0.0, 9400: 0.0, 9450: 0.0, 9500: 0.0, 9550: 0.0, 9600: 0.0, 9650: 0.0, 9700: 0.0, 9750: 0.0, 9800: 0.0, 9850: 0.0, 9900: 0.0, 9950: 0.0, 10000: 0.0, 10050: 0.0, 10100: 0.0, 10150: 0.0, 10200: 0.0, 10250: 0.0, 10300: 0.0, 10350: 0.0, 10400: 0.0, 10450: 0.0, 10500: 0.0, 10550: 0.0, 10600: 0.0, 10650: 0.0, 10700: 0.0, 10750: 0.0, 10800: 0.0, 10850: 0.0, 10900: 0.0, 10950: 0.0, 11000: 0.0, 11050: 0.0, 11100: 0.0, 11150: 0.0, 11200: 0.0, 11250: 0.0, 11300: 0.0, 11350: 0.0, 11400: 0.0, 11450: 0.0, 11500: 0.0, 11550: 0.0, 11600: 0.0, 11650: 0.0, 11700: 0.0, 11750: 0.0, 11800: 0.0, 11850: 0.0, 11900: 0.0, 11950: 0.0, 12000: 0.0, 12050: 0.0, 12100: 0.0, 12150: 0.0, 12200: 0.0, 12250: 0.0, 12300: 0.0, 12350: 0.0, 12400: 0.0, 12450: 0.0, 12500: 0.0, 12550: 0.0, 12600: 0.0, 12650: 0.0, 12700: 0.0, 12750: 0.0, 12800: 0.0, 12850: 0.0, 12900: 0.0, 12950: 0.0, 13000: 0.0, 13050: 0.0, 13100: 0.0, 13150: 0.0, 13200: 0.0, 13250: 0.0, 13300: 0.0, 13350: 0.0, 13400: 0.0, 13450: 0.0, 13500: 0.0, 13550: 0.0, 13600: 0.0, 13650: 0.0, 13700: 0.0, 13750: 0.0, 13800: 0.0, 13850: 0.0, 13900: 0.0, 13950: 0.0, 14000: 0.0, 14050: 0.0, 14100: 0.0, 14150: 0.0, 14200: 0.0, 14250: 0.0, 14300: 0.0, 14350: 0.5, 14400: 0.5, 14450: 0.0, 14500: 1.50125, 14550: 7.5050006, 14600: 32.998753, 14650: 69.00125, 14700: 82.99876, 14750: 89.50001, 14800: 90.50125, 14850: 94.00125, 14900: 97.99876, 14950: 97.00001, 15000: 93.005005, 15050: 96.50001, 15100: 94.00001, 15150: 96.50125, 15200: 95.50125, 15250: 96.00125, 15300: 95.0025, 15350: 97.497505, 15400: 98.0025, 15450: 100.497505, 15500: 96.99876, 15550: 102.997505, 15600: 100.505005, 15650: 103.50375, 15700: 104.00001, 15750: 106.496254, 15800: 105.5025, 15850: 106.50001, 15900: 104.50125, 15950: 103.49876, 16000: 108.50126, 16050: 108.0025, 16100: 110.50001, 16150: 109.505005, 16200: 110.497505, 16250: 110.00001, 16300: 109.50126, 16350: 109.5025, 16400: 107.00001, 16450: 109.00126, 16500: 110.00001, 16550: 111.49876, 16600: 111.00375, 16650: 106.00751, 16700: 109.49876, 16750: 110.00126, 16800: 112.00001, 16850: 114.49876, 16900: 110.00375, 16950: 115.0025, 17000: 112.00126, 17050: 112.497505, 17100: 114.0025, 17150: 116.50001, 17200: 115.00126, 17250: 111.00001, 17300: 113.497505, 17350: 116.997505, 17400: 110.50001, 17450: 113.50126, 17500: 115.505005, 17550: 113.00126, 17600: 115.496254, 17650: 111.00126, 17700: 115.00126, 17750: 112.506256, 17800: 115.005005, 17850: 114.0025, 17900: 117.00001, 17950: 113.50001, 18000: 115.50001, 18050: 117.495, 18100: 113.99876, 18150: 116.997505, 18200: 115.0025, 18250: 115.00001, 18300: 116.50126, 18350: 118.00126, 18400: 119.50001, 18450: 116.0025, 18500: 114.50375, 18550: 116.99876, 18600: 118.49876, 18650: 119.50001, 18700: 119.49876, 18750: 115.49876, 18800: 117.00126, 18850: 120.50001, 18900: 119.997505, 18950: 114.99876, 19000: 121.00001, 19050: 118.49876, 19100: 115.00126, 19150: 121.00001, 19200: 119.997505, 19250: 118.0025, 19300: 120.00126, 19350: 119.00126, 19400: 120.997505, 19450: 119.50375, 19500: 119.50126, 19550: 119.49876, 19600: 121.00001, 19650: 117.00126, 19700: 118.505005, 19750: 117.00375, 19800: 120.00001, 19850: 124.00375, 19900: 121.00126, 19950: 122.497505, 20000: 119.50001, 20050: 120.00001, 20100: 122.496254, 20150: 118.5025, 20200: 118.997505, 20250: 119.0025, 20300: 118.50126, 20350: 121.497505, 20400: 123.99251, 20450: 118.0025, 20500: 119.996254, 20550: 115.50126, 20600: 117.49876, 20650: 120.99876, 20700: 123.49876, 20750: 120.00126, 20800: 120.997505, 20850: 119.497505, 20900: 117.0025, 20950: 119.50126, 21000: 120.49876, 21050: 122.00001, 21100: 118.50001, 21150: 121.00001, 21200: 121.00126, 21250: 119.49876, 21300: 117.0025, 21350: 123.50126, 21400: 124.50001, 21450: 122.00001, 21500: 119.50001, 21550: 117.997505, 21600: 119.496254, 21650: 120.0025, 21700: 124.0025, 21750: 120.49876, 21800: 122.00001, 21850: 121.50126, 21900: 121.00001, 21950: 121.49876, 22000: 124.49876, 22050: 119.99876, 22100: 120.99876, 22150: 121.50126, 22200: 121.50001, 22250: 125.5025, 22300: 122.00001, 22350: 124.997505, 22400: 121.00001, 22450: 121.00001, 22500: 121.00001, 22550: 120.00126, 22600: 126.49876, 22650: 121.50001, 22700: 122.49876, 22750: 121.996254, 22800: 125.0025, 22850: 122.496254, 22900: 122.49876, 22950: 123.00001, 23000: 124.00126, 23050: 119.99876, 23100: 122.49876, 23150: 119.997505, 23200: 124.997505, 23250: 120.50001, 23300: 120.49876, 23350: 120.005005, 23400: 123.00375, 23450: 122.497505, 23500: 122.0025, 23550: 121.00001, 23600: 120.5025, 23650: 122.00001, 23700: 120.99876, 23750: 123.0025, 23800: 122.506256, 23850: 120.00001, 23900: 124.997505, 23950: 121.50126, 24000: 124.00126, 24050: 120.49876, 24100: 122.5025, 24150: 121.99376, 24200: 121.00375, 24250: 123.00001, 24300: 122.5025, 24350: 121.50001, 24400: 119.997505, 24450: 119.50126, 24500: 121.50126, 24550: 124.50001, 24600: 123.50126, 24650: 121.5025, 24700: 124.49876, 24750: 122.49876, 24800: 121.996254, 24850: 123.997505, 24900: 123.0025, 24950: 123.0025, 25000: 123.49876, 25050: 125.00001, 25100: 123.00126, 25150: 124.0025, 25200: 121.50001, 25250: 123.0025, 25300: 121.00001, 25350: 123.49876, 25400: 123.50375, 25450: 123.50001, 25500: 120.997505, 25550: 120.99876, 25600: 122.0025, 25650: 122.50001, 25700: 123.50126, 25750: 124.00001, 25800: 124.99876, 25850: 122.0025, 25900: 120.50001, 25950: 123.99876, 26000: 123.99876, 26050: 122.99876, 26100: 122.00001, 26150: 122.497505, 26200: 128.5, 26250: 123.50001, 26300: 124.49876, 26350: 122.997505, 26400: 123.006256, 26450: 122.00001, 26500: 122.50126, 26550: 123.50001, 26600: 123.99876, 26650: 122.99876, 26700: 120.50001, 26750: 125.00126, 26800: 121.0025, 26850: 122.496254, 26900: 119.00001, 26950: 122.496254, 27000: 125.00001, 27050: 124.996254, 27100: 121.5025, 27150: 125.00126, 27200: 123.00126, 27250: 120.50126, 27300: 127.99876, 27350: 121.50126, 27400: 124.00126, 27450: 120.997505, 27500: 122.49876, 27550: 124.50001, 27600: 122.00001, 27650: 122.99876, 27700: 124.00001, 27750: 124.00001, 27800: 126.00001, 27850: 120.5025, 27900: 123.996254, 27950: 123.497505, 28000: 121.00001, 28050: 121.506256, 28100: 124.50001, 28150: 121.497505, 28200: 124.496254, 28250: 122.50126, 28300: 125.00126, 28350: 125.496254, 28400: 124.00126, 28450: 122.50375, 28500: 123.497505, 28550: 124.00126, 28600: 123.00001, 28650: 123.50126, 28700: 122.0025, 28750: 121.50001, 28800: 120.99876, 28850: 126.996254, 28900: 124.497505, 28950: 123.997505, 29000: 125.99876, 29050: 123.497505, 29100: 120.49876, 29150: 124.99876, 29200: 122.996254, 29250: 124.997505, 29300: 123.99876, 29350: 123.00001, 29400: 123.00375, 29450: 123.00375, 29500: 122.50001, 29550: 123.00126, 29600: 125.505005, 29650: 124.505005, 29700: 120.0025, 29750: 124.50126, 29800: 122.00126, 29850: 124.00001, 29900: 122.49876, 29950: 122.50126, 30000: 122.49876, 30050: 125.50126, 30100: 122.00001, 30150: 122.5025, 30200: 123.497505, 30250: 122.99876, 30300: 122.00001, 30350: 122.00126, 30400: 124.00126, 30450: 122.50126, 30500: 122.00001, 30550: 123.0025, 30600: 123.00001, 30650: 121.997505, 30700: 122.50375, 30750: 124.99876, 30800: 124.496254, 30850: 124.50001, 30900: 123.005005, 30950: 124.50001, 31000: 122.0025, 31050: 122.50375, 31100: 124.99876, 31150: 124.49876, 31200: 125.00001, 31249: 123.496254}\n",
      "Key with the highest value: 26200, Value: 128.5\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "min_value = int(0e0)\n",
    "max_value = int(4e4)\n",
    "\n",
    "steps_per_seed = get_trained_steps(load_layout_name, load_datetime, mean_returns_per_seed, min_value, max_value, seed)\n",
    "print(steps_per_seed)\n",
    "\n",
    "# Get the key with the maximum value\n",
    "max_key = max(steps_per_seed, key=steps_per_seed.get)\n",
    "\n",
    "# Print the key and its corresponding value\n",
    "print(f\"Key with the highest value: {max_key}, Value: {steps_per_seed[max_key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING AND EVALUATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found checkpoint: trained_model_26200.pkl for step 26200\n",
      "Model parameters loaded from /mnt/lustre/home/samuloza/data/samuel_lozano/hfsp_collective_learning/data_overcooked_original/Asymmetric_Agents/custom_13/Checkpoints_2025-04-03_01-04-00/Seed_0/trained_model_26200.pkl\n",
      "Model restored successfully from step 26200\n",
      "with mean return 128.5!\n"
     ]
    }
   ],
   "source": [
    "fixed_step = 26200  # Change this to the desired step\n",
    "\n",
    "seed_idx = 0  # Change if needed\n",
    "\n",
    "#cluster = \"brigit\"\n",
    "#load_datetime = '2025-03-26_14-56-22'\n",
    "#load_layout_name = 'custom_8'\n",
    "custom_layout = load_custom_layout(load_layout_name)\n",
    "\n",
    "if cluster == \"cuenca\":\n",
    "    original_dir = f'/data/samuel_lozano/hfsp_collective_learning/data_switch_riddle/Asymmetric_Agents/{load_layout_name}/Checkpoints_{load_datetime}/'\n",
    "elif cluster == \"brigit\":\n",
    "    original_dir = f'/mnt/lustre/home/samuloza/data/samuel_lozano/hfsp_collective_learning/data_switch_riddle/Asymmetric_Agents/{load_layout_name}/Checkpoints_{load_datetime}/'\n",
    "else:\n",
    "    print(\"Introduce a valid cluster name\")\n",
    "\n",
    "load_dir = f\"{original_dir}Seed_{seed_idx}/\"\n",
    "load_filename = f\"trained_model_{fixed_step}.pkl\"\n",
    "\n",
    "num_actions = 6\n",
    "activation = \"tanh\"\n",
    "\n",
    "# Initialize network\n",
    "network_1 = ActorCritic(num_actions, activation)\n",
    "network_2 = ActorCritic(num_actions, activation)\n",
    "\n",
    "# Load parameters into the network\n",
    "model_params_1, model_params_2, closest_step = find_closest_checkpoint(fixed_step, load_dir)\n",
    "\n",
    "print(f\"Model restored successfully from step {closest_step}\")\n",
    "\n",
    "if 'mean_returns_per_seed' in locals() or 'mean_returns_per_seed' in globals():\n",
    "    return_value = f\"{mean_returns_per_seed[seed_idx][closest_step]:.3f}\".replace(\".\", \"_\")\n",
    "    print(f\"with mean return {float(mean_returns_per_seed[seed_idx][closest_step])}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of agents in environment: ['agent_0', 'agent_1']\n"
     ]
    }
   ],
   "source": [
    "# Set environment parameters\n",
    "max_steps = 1000\n",
    "key = jax.random.PRNGKey(0)\n",
    "key, key_r, key_a = jax.random.split(key, 3)\n",
    "\n",
    "\n",
    "# Instantiate environment\n",
    "env = make('switch_riddle', max_steps=max_steps)\n",
    "\n",
    "# Reset environment\n",
    "obs, state = env.reset(key_r)\n",
    "print('List of agents in environment:', env.agents)\n",
    "\n",
    "# Visualization setup\n",
    "viz = OvercookedVisualizer()\n",
    "state_seq = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run environment loop using the trained model\n",
    "for _ in range(max_steps):\n",
    "    state_seq.append(state)\n",
    "    \n",
    "    # Get model-based actions\n",
    "    key, key_s = jax.random.split(key)\n",
    "    \n",
    "    actions = {}\n",
    "    for i, agent in enumerate(env.agents):\n",
    "        agent_obs = obs[agent]  # Extract observation for each agent\n",
    "        \n",
    "        # Choose the correct network for the current agent\n",
    "        if i == 0:\n",
    "            action_logits, value = network_1.apply(model_params_1, agent_obs.flatten())  # Get model's action distribution\n",
    "        elif i == 1:\n",
    "            action_logits, value = network_2.apply(model_params_2, agent_obs.flatten())  # Get model's action distribution\n",
    "        \n",
    "        action = action_logits.sample(seed=key_s)\n",
    "        key, key_s = jax.random.split(key)\n",
    "\n",
    "        actions[agent] = action\n",
    "    \n",
    "    # Step environment\n",
    "    obs, state, rewards, dones, infos = env.step(key_s, state, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animation saved to /mnt/lustre/home/samuloza/data/samuel_lozano/hfsp_collective_learning/data_overcooked_original/Asymmetric_Agents/custom_13/Checkpoints_2025-04-03_01-04-00/Seed_0//animation_custom_13_trained_model_2025-04-03_01-04-00_step_26200_value_128_500.gif with adjusted speed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuloza/.conda/envs/JaxMARL/lib/python3.12/subprocess.py:1893: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _fork_exec(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP4 saved to /mnt/lustre/home/samuloza/data/samuel_lozano/hfsp_collective_learning/data_overcooked_original/Asymmetric_Agents/custom_13/Checkpoints_2025-04-03_01-04-00/Seed_0//animation_custom_13_trained_model_2025-04-03_01-04-00_step_26200_value_128_500.mp4\n"
     ]
    }
   ],
   "source": [
    "# FIX VISUALIZATION (SAVING IT WORKS)\n",
    "\n",
    "# Render to screen\n",
    "#for s in state_seq:\n",
    "#    viz.render(env.agent_view_size, s, highlight=False)\n",
    "#    time.sleep(0.1)\n",
    "\n",
    "# Save animation\n",
    "agent_view_size = 5\n",
    "\n",
    "output_filename = f\"{load_dir}/animation_{load_layout_name}_trained_model_{load_datetime}_step_{closest_step}_value_{return_value}.gif\"\n",
    "\n",
    "custom_animate(state_seq, agent_view_size=agent_view_size, filename=output_filename)\n",
    "\n",
    "print(f\"Animation saved to {output_filename} with adjusted speed\")\n",
    "\n",
    "gif_to_mp4(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaxMARL_TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
