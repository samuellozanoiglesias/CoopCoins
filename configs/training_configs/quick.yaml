# Quick training configuration for development
training:
  num_envs: 2
  num_inner_steps: 50
  num_epochs: 1000
  num_updates_per_epoch: 10
  show_every_n_epochs: 100
  save_every_n_epochs: 500

hyperparameters:
  learning_rate: 0.001
  gamma: 0.9
  gae_lambda: 0.95
  entropy_coef: 0.01
  clip_eps: 0.2
  vf_coef: 0.5
  max_grad_norm: 0.3
  minibatch_size: 5
  num_updates_per_minibatch: 4

environment:
  grid_size: 3
  payoff_matrix: [[1, 1, -2], [1, 1, -2]]
  reward_coef: [[1.0, 0.0], [1.0, 0.0]]  # Selfish agents
  dilemma: false

paths:
  save_dir: "./results/quick_training"
  log_dir: "./logs" 