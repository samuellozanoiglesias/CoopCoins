{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bfe3888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA backend failed to initialize: Unable to use CUDA because of the following issues with CUDA components:\n",
      "Outdated CUDA installation found.\n",
      "Version JAX was built against: 12030\n",
      "Minimum supported: 12010\n",
      "Installed version: 12000\n",
      "The local installation version must be no lower than 12010.\n",
      "--------------------------------------------------\n",
      "Outdated cuBLAS installation found.\n",
      "Version JAX was built against: 120304\n",
      "Minimum supported: 120100\n",
      "Installed version: 120002\n",
      "The local installation version must be no lower than 120100.\n",
      "--------------------------------------------------\n",
      "Outdated cuSPARSE installation found.\n",
      "Version JAX was built against: 12200\n",
      "Minimum supported: 12100\n",
      "Installed version: 12001\n",
      "The local installation version must be no lower than 12100..(Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import optax\n",
    "from jaxmarl import make\n",
    "from functools import partial\n",
    "\n",
    "# HiperparÃ¡metros\n",
    "NUM_ENVS = 4\n",
    "NUM_STEPS = 1000\n",
    "NUM_AGENTS = 3\n",
    "LR = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed1f90a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CoinGame.__init__() got an unexpected keyword argument 'num_agents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Crear entornos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m keys \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m), NUM_ENVS)\n\u001b[0;32m----> 3\u001b[0m envs \u001b[38;5;241m=\u001b[39m [make(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoin_game\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_agents\u001b[38;5;241m=\u001b[39mNUM_AGENTS) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_ENVS)]\n\u001b[1;32m      4\u001b[0m states \u001b[38;5;241m=\u001b[39m [env\u001b[38;5;241m.\u001b[39mreset(k)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m env, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(envs, keys)]\n\u001b[1;32m      5\u001b[0m obs \u001b[38;5;241m=\u001b[39m [env\u001b[38;5;241m.\u001b[39mreset(k)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m env, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(envs, keys)]\n",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Crear entornos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m keys \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m), NUM_ENVS)\n\u001b[0;32m----> 3\u001b[0m envs \u001b[38;5;241m=\u001b[39m [\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoin_game\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_agents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_AGENTS\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_ENVS)]\n\u001b[1;32m      4\u001b[0m states \u001b[38;5;241m=\u001b[39m [env\u001b[38;5;241m.\u001b[39mreset(k)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m env, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(envs, keys)]\n\u001b[1;32m      5\u001b[0m obs \u001b[38;5;241m=\u001b[39m [env\u001b[38;5;241m.\u001b[39mreset(k)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m env, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(envs, keys)]\n",
      "File \u001b[0;32m~/hfsp_overcooked_mod/JaxMARL/jaxmarl/registration.py:111\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(env_id, **env_kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# 8. Coin Game\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m env_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoin_game\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 111\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mCoinGame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43menv_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# 9. JaxNav\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m env_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjaxnav\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: CoinGame.__init__() got an unexpected keyword argument 'num_agents'"
     ]
    }
   ],
   "source": [
    "# Crear entornos\n",
    "keys = jax.random.split(jax.random.PRNGKey(0), NUM_ENVS)\n",
    "envs = [make(\"coin_game\", num_agents=NUM_AGENTS) for _ in range(NUM_ENVS)]\n",
    "states = [env.reset(k)[1] for env, k in zip(envs, keys)]\n",
    "obs = [env.reset(k)[0] for env, k in zip(envs, keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === NETWORK DEFINITION ===\n",
    "def net_fn(obs):\n",
    "    mlp = hk.Sequential([\n",
    "        hk.Flatten(),\n",
    "        hk.nets.MLP([32, 32]),\n",
    "    ])\n",
    "    hidden = mlp(obs)\n",
    "    logits = hk.Linear(5)(hidden)  # Assume 5 discrete actions\n",
    "    value = hk.Linear(1)(hidden)\n",
    "    return logits, value\n",
    "\n",
    "def make_policy():\n",
    "    return hk.transform(net_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INIT NETWORKS, OPTIMIZERS ===\n",
    "policy_fns = {}\n",
    "params = {}\n",
    "opt_state = {}\n",
    "optimizers = {}\n",
    "for i in range(NUM_AGENTS):\n",
    "    agent = f\"agent_{i}\"\n",
    "    policy = make_policy()\n",
    "    policy_fns[agent] = policy\n",
    "    dummy_obs = jnp.zeros((1, *envs[0].observation_space(agent).shape))\n",
    "    params[agent] = policy.init(jax.random.PRNGKey(42 + i), dummy_obs)\n",
    "    optimizers[agent] = optax.adam(LR)\n",
    "    opt_state[agent] = optimizers[agent].init(params[agent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ACTION FUNCTION ===\n",
    "def select_action(params, obs, key, policy_fn):\n",
    "    logits, value = policy_fn.apply(params, key, obs)\n",
    "    action = jax.random.categorical(key, logits)\n",
    "    log_prob = jax.nn.log_softmax(logits)[0, action]\n",
    "    return action, value[0, 0], log_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd5356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOSS FUNCTION ===\n",
    "def loss_fn(params, key, obs, action, advantage, old_log_prob, returns, policy_fn):\n",
    "    logits, value = policy_fn.apply(params, key, obs)\n",
    "    log_probs = jax.nn.log_softmax(logits)\n",
    "    new_log_prob = log_probs[0, action]\n",
    "    ratio = jnp.exp(new_log_prob - old_log_prob)\n",
    "    clipped_ratio = jnp.clip(ratio, 0.8, 1.2)\n",
    "    actor_loss = -jnp.minimum(ratio * advantage, clipped_ratio * advantage)\n",
    "    critic_loss = (returns - value[0, 0]) ** 2\n",
    "    loss = actor_loss + 0.5 * critic_loss\n",
    "    return loss.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e3c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: reward[agent_0] = 0.00\n",
      "Step 100: reward[agent_0] = 0.00\n",
      "Step 200: reward[agent_0] = 0.00\n",
      "Step 300: reward[agent_0] = 0.00\n",
      "Step 400: reward[agent_0] = 0.00\n"
     ]
    }
   ],
   "source": [
    "# === TRAINING LOOP ===\n",
    "for step in range(NUM_STEPS):\n",
    "    for env_idx, env in enumerate(envs):\n",
    "        state = states[env_idx]\n",
    "        obs_env = obs[env_idx]\n",
    "        key = jax.random.PRNGKey(step * 100 + env_idx)\n",
    "\n",
    "        actions = {}\n",
    "        values = {}\n",
    "        log_probs = {}\n",
    "\n",
    "        for i, agent in enumerate(env.agents):\n",
    "            obs_agent = jnp.array(obs_env[agent])[None, ...]\n",
    "            key, subkey = jax.random.split(key)\n",
    "            action, value, log_prob = select_action(params[agent], obs_agent, subkey, policy_fns[agent])\n",
    "            actions[agent] = action\n",
    "            values[agent] = value\n",
    "            log_probs[agent] = log_prob\n",
    "\n",
    "        obs_next, state_next, reward, done, info = env.step(key, state, actions)\n",
    "\n",
    "        # PPO step (1-step, advantage = reward - value)\n",
    "        for agent in env.agents:\n",
    "            obs_agent = jnp.array(obs_env[agent])[None, ...]\n",
    "            rew = reward[agent]\n",
    "            advantage = rew - values[agent]\n",
    "            returns = rew\n",
    "\n",
    "            grads = jax.grad(loss_fn)(\n",
    "                params[agent], subkey, obs_agent, actions[agent], advantage,\n",
    "                log_probs[agent], returns, policy_fns[agent]\n",
    "            )\n",
    "\n",
    "            updates, opt_state[agent] = optimizers[agent].update(grads, opt_state[agent])\n",
    "            params[agent] = optax.apply_updates(params[agent], updates)\n",
    "\n",
    "        # Update env state\n",
    "        states[env_idx] = state_next\n",
    "        obs[env_idx] = obs_next\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}: reward[agent_0] = {reward['agent_0']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430ae98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaxMARL_TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
