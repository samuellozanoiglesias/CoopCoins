{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import numpy as np\n",
    "from jaxmarl.environments.coin_game.make_train_RLLIB import make_train_RLLIB        \n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperpar√°metros\n",
    "NUM_ENVS = 1\n",
    "NUM_INNER_STEPS = 128\n",
    "NUM_EPOCHS = 3000\n",
    "NUM_AGENTS = 2\n",
    "SHOW_EVERY_N_EPOCHS = 100\n",
    "SAVE_EVERY_N_EPOCHS = 500\n",
    "LR = 1e-4\n",
    "PAYOFF_MATRIX = [[1, 2, -3], [1, 2, -3]]\n",
    "GRID_SIZE = 3\n",
    "REWARD_COEF = [[1, 0], [1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _posixsubprocess.fork_exec(\n",
      "2025-06-17 14:10:29,868\tINFO worker.py:1917 -- Started a local Ray instance.\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m 2025-06-17 14:10:43,896\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m 2025-06-17 14:10:43,896\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-06-17 14:10:48,988\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0.0, 1.0, (36,), float32), Discrete(5)), 'agent_1': (Box(0.0, 1.0, (36,), float32), Discrete(5)), '__env__': (Dict('agent_0': Box(0.0, 1.0, (36,), float32), 'agent_1': Box(0.0, 1.0, (36,), float32)), Dict('agent_0': Discrete(5), 'agent_1': Discrete(5)))}\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m 2025-06-17 14:10:48,969\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m 2025-06-17 14:10:48,969\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m 2025-06-17 14:10:48,978\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m 2025-06-17 14:10:48,979\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m 2025-06-17 14:10:48,979\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m 2025-06-17 14:10:48,979\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m 2025-06-17 14:10:48,979\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m 2025-06-17 14:10:48,979\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m         ImmutableActionsConnector\n",
      "2025-06-17 14:10:49,036\tINFO policy.py:1234 -- Policy (worker=local) running on CPU.\n",
      "2025-06-17 14:10:49,038\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-06-17 14:10:51,255\tINFO policy.py:1234 -- Policy (worker=local) running on CPU.\n",
      "2025-06-17 14:10:51,257\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-06-17 14:10:51,268\tINFO util.py:118 -- Using connectors:\n",
      "2025-06-17 14:10:51,269\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-06-17 14:10:51,270\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-06-17 14:10:51,272\tINFO util.py:118 -- Using connectors:\n",
      "2025-06-17 14:10:51,272\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-06-17 14:10:51,273\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-06-17 14:10:51,273\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_1', 'agent_0']>\n",
      "2025-06-17 14:10:51,274\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-06-17 14:10:51,275\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-06-17 14:10:51,305\tINFO policy.py:1234 -- Policy (worker=local) running on CPU.\n",
      "2025-06-17 14:10:51,306\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-06-17 14:10:51,322\tINFO policy.py:1234 -- Policy (worker=local) running on CPU.\n",
      "2025-06-17 14:10:51,323\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-06-17 14:10:51,331\tINFO util.py:118 -- Using connectors:\n",
      "2025-06-17 14:10:51,331\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-06-17 14:10:51,332\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-06-17 14:10:51,333\tINFO util.py:118 -- Using connectors:\n",
      "2025-06-17 14:10:51,334\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-06-17 14:10:51,335\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-06-17 14:10:51,335\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_1', 'agent_0']>\n",
      "2025-06-17 14:10:51,336\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-06-17 14:10:51,336\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-06-17 14:10:51,341\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0.0, 1.0, (36,), float32), Discrete(5)), 'agent_1': (Box(0.0, 1.0, (36,), float32), Discrete(5)), '__env__': (Dict('agent_0': Box(0.0, 1.0, (36,), float32), 'agent_1': Box(0.0, 1.0, (36,), float32)), Dict('agent_0': Discrete(5), 'agent_1': Discrete(5)))}\n",
      "2025-06-17 14:10:51,342\tINFO trainable.py:160 -- Trainable.setup took 19.449 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m 2025-06-17 14:10:51,611\tINFO rollout_worker.py:671 -- Generating sample batch of size 128\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m 2025-06-17 14:10:51,623\tERROR actor_manager.py:187 -- Worker exception caught during `apply()`: 'CoinGameEnvRLLIB' object has no attribute 'agent_selection'\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py\", line 183, in apply\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     return func(self, *args, **kwargs)\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py\", line 108, in <lambda>\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     (lambda w: w.sample(**random_action_kwargs))\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py\", line 463, in _resume_span\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 677, in sample\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     batches = [self.input_reader.next()]\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 59, in next\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     batches = [self.get_data()]\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/evaluation/sampler.py\", line 225, in get_data\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     item = next(self._env_runner)\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 329, in run\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     outputs = self.step()\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/evaluation/env_runner_v2.py\", line 348, in step\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     ) = self._base_env.poll()\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 530, in poll\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     ) = env_state.poll()\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 717, in poll\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     self.reset()\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 801, in reset\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     raise e\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env.py\", line 795, in reset\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     obs_and_infos = self.env.reset(seed=seed, options=options)\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m   File \"/mnt/lustre/home/samuloza/.conda/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/env/wrappers/pettingzoo_env.py\", line 147, in reset\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m     {self.env.agent_selection: self.env.observe(self.env.agent_selection)},\n",
      "\u001b[36m(RolloutWorker pid=3438578)\u001b[0m AttributeError: 'CoinGameEnvRLLIB' object has no attribute 'agent_selection'\n",
      "2025-06-17 14:11:51,617\tWARNING rollout_ops.py:121 -- No samples returned from remote workers. If you have a slow environment or model, consider increasing the `sample_timeout_s` or decreasing the `rollout_fragment_length` in `AlgorithmConfig.env_runners().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff4bce06bc75bc1d215b9e201101000000 Worker ID: 1ca30edd9b19394374707622cca8a87887ef3ff842bc641d5b900174 Node ID: ba8b85d44b039aed2b3443bb837440bbb40b79bea458869b71a40b42 Worker IP address: 147.96.240.246 Worker port: 39175 Worker PID: 3438578 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 14:11:53,024\tERROR actor_manager.py:873 -- Ray error (The actor 4bce06bc75bc1d215b9e201101000000 is unavailable: The actor is temporarily unavailable: IOError: Fail all inflight tasks due to actor state change.. The task may or maynot have been executed on the actor.), taking actor 1 out of service.\n",
      "2025-06-17 14:11:53,026\tERROR actor_manager.py:674 -- The actor 4bce06bc75bc1d215b9e201101000000 is unavailable: The actor is temporarily unavailable: IOError: Fail all inflight tasks due to actor state change.. The task may or maynot have been executed on the actor.\n",
      "NoneType: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'episode_reward_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m      3\u001b[0m current_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUM_ENVS\u001b[39m\u001b[38;5;124m\"\u001b[39m: NUM_ENVS,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUM_INNER_STEPS\u001b[39m\u001b[38;5;124m\"\u001b[39m: NUM_INNER_STEPS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVF_COEF\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.5\u001b[39m  \u001b[38;5;66;03m# Value function coefficient\u001b[39;00m\n\u001b[1;32m     24\u001b[0m }\n\u001b[0;32m---> 26\u001b[0m trainer, current_date \u001b[38;5;241m=\u001b[39m \u001b[43mmake_train_RLLIB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/lustre/home/samuloza/hfsp_overcooked_mod/JaxMARL/jaxmarl/environments/coin_game/make_train_RLLIB.py:107\u001b[0m, in \u001b[0;36mmake_train_RLLIB\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSHOW_EVERY_N_EPOCHS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode reward mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepisode_reward_mean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode length mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_len_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Extract and log detailed metrics\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'episode_reward_mean'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m 2025-06-17 14:12:04,141\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m 2025-06-17 14:12:04,141\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m 2025-06-17 14:12:06,904\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m 2025-06-17 14:12:06,904\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m 2025-06-17 14:12:06,913\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m 2025-06-17 14:12:06,914\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m 2025-06-17 14:12:06,914\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m 2025-06-17 14:12:06,914\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m 2025-06-17 14:12:06,915\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m 2025-06-17 14:12:06,915\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3438577)\u001b[0m         ImmutableActionsConnector\n"
     ]
    }
   ],
   "source": [
    "brigit = '/mnt/lustre/home/samuloza'\n",
    "save_dir = f'{brigit}/data/samuel_lozano/coin_game/pruebas/Prisioner_dilemma/'\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "config = {\n",
    "    \"NUM_ENVS\": NUM_ENVS,\n",
    "    \"NUM_INNER_STEPS\": NUM_INNER_STEPS,\n",
    "    \"NUM_EPOCHS\": NUM_EPOCHS,\n",
    "    \"NUM_AGENTS\": NUM_AGENTS,\n",
    "    \"SHOW_EVERY_N_EPOCHS\": SHOW_EVERY_N_EPOCHS,\n",
    "    \"SAVE_EVERY_N_EPOCHS\": SAVE_EVERY_N_EPOCHS,\n",
    "    \"LR\": LR,\n",
    "    \"PAYOFF_MATRIX\": PAYOFF_MATRIX,\n",
    "    \"GRID_SIZE\": GRID_SIZE,\n",
    "    \"REWARD_COEF\": REWARD_COEF,\n",
    "    \"SAVE_DIR\": save_dir,\n",
    "    # RLlib specific parameters\n",
    "    \"NUM_UPDATES\": 10,  # Number of updates of the policy\n",
    "    \"GAMMA\": 0.995,  # Discount factor\n",
    "    \"GAE_LAMBDA\": 0.95,  # GAE-Lambda parameter\n",
    "    \"ENT_COEF\": 0.01,  # Entropy coefficient\n",
    "    \"CLIP_EPS\": 0.2,  # PPO clip parameter\n",
    "    \"VF_COEF\": 0.5  # Value function coefficient\n",
    "}\n",
    "\n",
    "trainer, current_date = make_train_RLLIB(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaxMARL_TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
