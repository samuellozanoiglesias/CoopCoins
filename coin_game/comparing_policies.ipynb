{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-07-10 00:35:11,308:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "from jaxmarl.environments.coin_game.coin_game_rllib_env import CoinGameRLLibEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH SETTINGS\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(env_config):\n",
    "    return CoinGameRLLibEnv(**env_config)\n",
    "\n",
    "register_env(\"coin_game_env_RLLIB\", env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local = '/mnt/lustre/home/samuloza'\n",
    "local = '/home/samuel_lozano'\n",
    "#local = 'C:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado'\n",
    "\n",
    "DILEMMA = 0\n",
    "extra_info = 'Individual'\n",
    "MAIN_PATH = f\"{local}/data/samuel_lozano/CoopCoins/RLLIB/{extra_info}\"\n",
    "\n",
    "if DILEMMA == 1:\n",
    "    BASE_PATH = f\"{MAIN_PATH}/Prisioner_dilemma\"\n",
    "elif DILEMMA == 0:\n",
    "    BASE_PATH = f\"{MAIN_PATH}/No_dilemma\"\n",
    "\n",
    "REWARD_ATTITUDE_PAIRS = [\n",
    "    ('cooperative', 'individualistic'),\n",
    "    ('competitive', 'individualistic'),\n",
    "    # Add more pairs as needed\n",
    "]\n",
    "\n",
    "CHECKPOINT = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attitudes = {\n",
    "    \"individualistic\": (1.0, 0.0),\n",
    "    \"cooperative\": (0.707, 0.707),\n",
    "    \"competitive\": (0.707, -0.707)\n",
    "}\n",
    "\n",
    "attitude_names = {v: k for k, v in attitudes.items()}\n",
    "\n",
    "# Automatically build REWARD_COEFS from attitude names\n",
    "REWARD_COEFS = [\n",
    "    [list(attitudes[a1]), list(attitudes[a2])] for (a1, a2) in REWARD_ATTITUDE_PAIRS\n",
    "]\n",
    "\n",
    "REWARD_ATTITUDE_PAIRS = REWARD_ATTITUDE_PAIRS + [(b, a) for (a, b) in REWARD_ATTITUDE_PAIRS]\n",
    "\n",
    "# Add reversed pairs automatically\n",
    "REWARD_COEFS += [[pair[1], pair[0]] for pair in REWARD_COEFS]\n",
    "\n",
    "# Helper to match coefs up to 3 decimals\n",
    "def match_coef(row, coef):\n",
    "    return np.isclose(row['OWN_REWARD_COEF_ALPHA'], coef[0], atol=1e-3) and np.isclose(row['OWN_REWARD_COEF_BETA'], coef[1], atol=1e-3)\n",
    "\n",
    "def match_other_coef(row, coef):\n",
    "    return np.isclose(row['OTHER_REWARD_COEF_ALPHA'], coef[0], atol=1e-3) and np.isclose(row['OTHER_REWARD_COEF_BETA'], coef[1], atol=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVES = np.array([\n",
    "    [0, 1],   # right\n",
    "    [0, -1],  # left\n",
    "    [1, 0],   # up\n",
    "    [-1, 0],  # down\n",
    "    [0, 0],   # stay\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer el REWARD_COEF de un config.txt\n",
    "def get_reward_coef(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip().startswith('REWARD_COEF'):\n",
    "                # Extrae la parte después del igual\n",
    "                coef_str = line.split(':', 1)[1].strip()\n",
    "                try:\n",
    "                    coef = ast.literal_eval(coef_str)\n",
    "                    return coef\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing REWARD_COEF in {config_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "def coefs_equal_3dec(a, b):\n",
    "    return all(\n",
    "        round(x, 3) == round(y, 3)\n",
    "        for row_a, row_b in zip(a, b)\n",
    "        for x, y in zip(row_a, row_b)\n",
    "    )\n",
    "\n",
    "# Busca los directorios que contienen los REWARD_COEF deseados\n",
    "def find_training_dirs():\n",
    "    matches = {}\n",
    "    for dir_name in os.listdir(BASE_PATH):\n",
    "        dir_path = os.path.join(BASE_PATH, dir_name)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            continue\n",
    "        config_path = os.path.join(dir_path, 'config.txt')\n",
    "        if not os.path.exists(config_path):\n",
    "            continue\n",
    "        coef = get_reward_coef(config_path)\n",
    "        for target in REWARD_COEFS:\n",
    "            if coefs_equal_3dec(coef, target):\n",
    "                key = str(target)\n",
    "                if key not in matches:\n",
    "                    matches[key] = []\n",
    "                matches[key].append(dir_path)\n",
    "    return matches\n",
    "\n",
    "# Carga la política del segundo agente desde un checkpoint RLlib\n",
    "def load_policy(checkpoint_dir, agent_id):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{CHECKPOINT}')\n",
    "    # RLlib guarda un archivo extra con el nombre completo\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        # Busca el archivo real\n",
    "        for f in os.listdir(checkpoint_dir):\n",
    "            if f.startswith(f'checkpoint_{CHECKPOINT}'):\n",
    "                checkpoint_path = os.path.join(checkpoint_dir, f)\n",
    "                break\n",
    "    # Carga el modelo con la API moderna\n",
    "    algo = Algorithm.from_checkpoint(checkpoint_path)\n",
    "    policy = algo.get_policy(f\"agent_{agent_id}\")\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_obs(state, grid_size=3):\n",
    "    \"\"\"\n",
    "    state: dict with keys 'red_pos', 'blue_pos', 'red_coin_pos', 'blue_coin_pos'\n",
    "           each value is a tuple (x, y)\n",
    "    Returns: {'agent_0': obs0, 'agent_1': obs1}\n",
    "    \"\"\"\n",
    "    obs1 = np.zeros((grid_size, grid_size, 4), dtype=np.int8)\n",
    "    obs2 = np.zeros((grid_size, grid_size, 4), dtype=np.int8)\n",
    "    # Fill channels for agent_0\n",
    "    obs1[state['red_pos'][0], state['red_pos'][1], 0] = 1\n",
    "    obs1[state['blue_pos'][0], state['blue_pos'][1], 1] = 1\n",
    "    obs1[state['red_coin_pos'][0], state['red_coin_pos'][1], 2] = 1\n",
    "    obs1[state['blue_coin_pos'][0], state['blue_coin_pos'][1], 3] = 1\n",
    "    # For agent_1, swap red/blue and red_coin/blue_coin channels\n",
    "    obs2[:, :, 0] = obs1[:, :, 1]  # blue\n",
    "    obs2[:, :, 1] = obs1[:, :, 0]  # red\n",
    "    obs2[:, :, 2] = obs1[:, :, 3]  # blue_coin\n",
    "    obs2[:, :, 3] = obs1[:, :, 2]  # red_coin\n",
    "    return {\n",
    "        'agent_0': obs1.flatten(),\n",
    "        'agent_1': obs2.flatten()\n",
    "    }\n",
    "\n",
    "def generate_all_valid_states(grid_size=3):\n",
    "    positions = [(i, j) for i in range(grid_size) for j in range(grid_size)]\n",
    "    states = []\n",
    "    for red_pos in positions:\n",
    "        for blue_pos in positions:\n",
    "            if blue_pos == red_pos:\n",
    "                continue\n",
    "            for red_coin_pos in positions:\n",
    "                if red_coin_pos == red_pos or red_coin_pos == blue_pos:\n",
    "                    continue\n",
    "                for blue_coin_pos in positions:\n",
    "                    if blue_coin_pos in [red_pos, blue_pos, red_coin_pos]:\n",
    "                        continue\n",
    "                    state = {\n",
    "                        'red_pos': red_pos,\n",
    "                        'blue_pos': blue_pos,\n",
    "                        'red_coin_pos': red_coin_pos,\n",
    "                        'blue_coin_pos': blue_coin_pos\n",
    "                    }\n",
    "                    states.append(state)\n",
    "    return states\n",
    "\n",
    "def simple_adjacent(pos1, pos2, grid_size):\n",
    "    return abs(pos1[0] - pos2[0]) + abs(pos1[1] - pos2[1]) == 1\n",
    "\n",
    "def toroidal_adjacent(pos1, pos2, grid_size):\n",
    "    dx = min(abs(pos1[0] - pos2[0]), grid_size - abs(pos1[0] - pos2[0]))\n",
    "    dy = min(abs(pos1[1] - pos2[1]), grid_size - abs(pos1[1] - pos2[1]))\n",
    "    return (dx == 1 and dy == 0) or (dx == 0 and dy == 1)\n",
    "\n",
    "def classify_action(obs, action, grid_size=3):\n",
    "    obs = np.array(obs).reshape((grid_size, grid_size, 4))\n",
    "    # Channel 0: agent, 1: other agent, 2: own coin, 3: other coin\n",
    "    agent_pos = np.argwhere(obs[:, :, 0] == 1)[0]\n",
    "    own_coin_pos = np.argwhere(obs[:, :, 2] == 1)[0]\n",
    "    other_coin_pos = np.argwhere(obs[:, :, 3] == 1)[0]\n",
    "    move = MOVES[action]\n",
    "    new_pos = (agent_pos + move) % grid_size\n",
    "    result = [0, 0, 0, 0, 0]\n",
    "    if np.array_equal(new_pos, own_coin_pos):\n",
    "        result[0] = 1\n",
    "    elif np.array_equal(new_pos, other_coin_pos):\n",
    "        result[1] = 1\n",
    "    else:\n",
    "        own_adjacent = toroidal_adjacent(agent_pos, own_coin_pos, grid_size)\n",
    "        other_adjacent = toroidal_adjacent(agent_pos, other_coin_pos, grid_size)\n",
    "        if own_adjacent:\n",
    "            result[2] = 1\n",
    "        elif other_adjacent:\n",
    "            result[3] = 1\n",
    "        else:\n",
    "            result[4] = 1\n",
    "    return result\n",
    "\n",
    "def extract_policy_to_csv(policy, output_csv, agent_id=0, grid_size=3):\n",
    "    states = generate_all_valid_states(grid_size)\n",
    "    with open(output_csv, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(\n",
    "            [f'obs_{i}' for i in range(grid_size*grid_size*4)] +\n",
    "            ['action',\n",
    "             'own_coin_collected', 'other_coin_collected',\n",
    "             'reject_own_coin', 'reject_other_coin', 'no_coin_visible']\n",
    "        )\n",
    "        for state in states:\n",
    "            obs_dict = state_to_obs(state)  # returns dict for both agents\n",
    "            obs = obs_dict[f'agent_{agent_id}']\n",
    "            action = policy.compute_single_action(obs)\n",
    "            if isinstance(action, tuple):\n",
    "                action_val = action[0]\n",
    "            else:\n",
    "                action_val = action\n",
    "            metrics = classify_action(np.array(obs), action_val, grid_size=grid_size)\n",
    "            writer.writerow(list(obs) + [action_val] + metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL POLICY CSV GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = find_training_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Procesando REWARD_COEF=[[0.707, 0.707], [1.0, 0.0]] ===\n",
      "\n",
      "--- Training directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-32-43 ---\n",
      "Checkpoint directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-32-43/checkpoint_5000\n",
      "Config:\n",
      "NUM_ENVS: 1\n",
      "NUM_INNER_STEPS: 150\n",
      "NUM_EPOCHS: 5000\n",
      "NUM_AGENTS: 2\n",
      "SHOW_EVERY_N_EPOCHS: 1000\n",
      "SAVE_EVERY_N_EPOCHS: 500\n",
      "LR: 0.0003\n",
      "PAYOFF_MATRIX: [[1, 1, -2], [1, 1, -2]]\n",
      "GRID_SIZE: 3\n",
      "REWARD_COEF: [[0.707107, 0.707107], [1.0, 0.0]]\n",
      "SAVE_DIR: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma\n",
      "NUM_UPDATES: 4\n",
      "GAMMA: 0.9\n",
      "GAE_LAMBDA: 0.95\n",
      "ENT_COEF: 0.05\n",
      "CLIP_EPS: 0.2\n",
      "VF_COEF: 0.5\n",
      "SEED: 2\n",
      "PATH: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma/Training_2025-07-08_21-32-43\n",
      "\n",
      "Loading policy for agent 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _posixsubprocess.fork_exec(\n",
      "2025-07-10 00:35:15,696\tINFO worker.py:1917 -- Started a local Ray instance.\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m WARNING:2025-07-10 00:35:19,045:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m 2025-07-10 00:35:21,162\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m 2025-07-10 00:35:21,162\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m 2025-07-10 00:35:22,504\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m 2025-07-10 00:35:22,504\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:35:22,514\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fc168731930>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fc168731930>>)}\n",
      "2025-07-10 00:35:22,552\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:35:22,553\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m 2025-07-10 00:35:22,508\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m 2025-07-10 00:35:22,508\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m 2025-07-10 00:35:22,508\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m 2025-07-10 00:35:22,508\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m 2025-07-10 00:35:22,508\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m 2025-07-10 00:35:22,508\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2140)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:35:24,174\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:35:24,175\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:35:24,190\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:35:24,191\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:35:24,191\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:35:24,192\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:35:24,192\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:35:24,192\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:35:24,193\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:35:24,194\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:35:24,194\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:35:24,204\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:35:24,205\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:35:24,215\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:35:24,216\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:35:24,224\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:35:24,225\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:35:24,225\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:35:24,226\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:35:24,226\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:35:24,227\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:35:24,227\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:35:24,228\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:35:24,228\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:35:24,232\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe43223520>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe43223520>>)}\n",
      "2025-07-10 00:35:24,233\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 0.\n",
      "Saving CSV for agent 0 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-32-43/policy_agent_0_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-32-43/policy_agent_0_checkpoint_5000.csv\n",
      "Loading policy for agent 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m WARNING:2025-07-10 00:35:33,078:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m 2025-07-10 00:35:35,156\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m 2025-07-10 00:35:35,156\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:35:35,950\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe4294a5f0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe4294a5f0>>)}\n",
      "2025-07-10 00:35:35,957\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:35:35,958\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:35:35,986\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:35:35,987\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:35:36,010\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:35:36,011\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:35:36,011\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m 2025-07-10 00:35:35,940\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m 2025-07-10 00:35:35,940\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m 2025-07-10 00:35:35,943\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m 2025-07-10 00:35:35,943\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m 2025-07-10 00:35:35,943\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m 2025-07-10 00:35:35,944\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m 2025-07-10 00:35:35,944\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m 2025-07-10 00:35:35,944\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2141)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:35:36,012\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:35:36,013\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:35:36,013\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:35:36,014\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:35:36,015\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:35:36,015\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:35:36,024\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:35:36,024\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:35:36,037\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:35:36,038\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:35:36,050\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:35:36,051\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:35:36,051\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:35:36,052\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:35:36,053\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:35:36,054\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:35:36,054\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:35:36,055\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:35:36,055\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:35:36,058\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe4296ab30>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe4296ab30>>)}\n",
      "2025-07-10 00:35:36,059\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 1.\n",
      "Saving CSV for agent 1 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-32-43/policy_agent_1_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-32-43/policy_agent_1_checkpoint_5000.csv\n",
      "\n",
      "--- Training directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-58-21 ---\n",
      "Checkpoint directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-58-21/checkpoint_5000\n",
      "Config:\n",
      "NUM_ENVS: 1\n",
      "NUM_INNER_STEPS: 150\n",
      "NUM_EPOCHS: 5000\n",
      "NUM_AGENTS: 2\n",
      "SHOW_EVERY_N_EPOCHS: 1000\n",
      "SAVE_EVERY_N_EPOCHS: 500\n",
      "LR: 0.0003\n",
      "PAYOFF_MATRIX: [[1, 1, -2], [1, 1, -2]]\n",
      "GRID_SIZE: 3\n",
      "REWARD_COEF: [[0.707107, 0.707107], [1.0, 0.0]]\n",
      "SAVE_DIR: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma\n",
      "NUM_UPDATES: 4\n",
      "GAMMA: 0.9\n",
      "GAE_LAMBDA: 0.95\n",
      "ENT_COEF: 0.05\n",
      "CLIP_EPS: 0.2\n",
      "VF_COEF: 0.5\n",
      "SEED: 3\n",
      "PATH: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma/Training_2025-07-09_02-58-21\n",
      "\n",
      "Loading policy for agent 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m WARNING:2025-07-10 00:35:46,019:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m 2025-07-10 00:35:48,244\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m 2025-07-10 00:35:48,245\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:35:49,022\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe432ddfc0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe432ddfc0>>)}\n",
      "2025-07-10 00:35:49,028\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:35:49,029\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:35:49,043\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:35:49,043\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:35:49,054\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:35:49,054\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:35:49,055\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:35:49,056\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:35:49,056\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:35:49,056\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:35:49,057\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:35:49,057\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:35:49,058\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:35:49,067\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:35:49,068\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:35:49,078\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:35:49,079\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:35:49,086\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:35:49,087\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:35:49,087\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:35:49,088\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:35:49,088\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:35:49,089\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:35:49,089\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:35:49,089\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:35:49,090\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:35:49,093\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe4189dc30>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe4189dc30>>)}\n",
      "2025-07-10 00:35:49,094\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m 2025-07-10 00:35:49,012\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m 2025-07-10 00:35:49,012\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m 2025-07-10 00:35:49,016\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m 2025-07-10 00:35:49,016\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m 2025-07-10 00:35:49,016\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m 2025-07-10 00:35:49,016\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m 2025-07-10 00:35:49,016\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m 2025-07-10 00:35:49,016\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2144)\u001b[0m         ImmutableActionsConnector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 0.\n",
      "Saving CSV for agent 0 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-58-21/policy_agent_0_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-58-21/policy_agent_0_checkpoint_5000.csv\n",
      "Loading policy for agent 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m WARNING:2025-07-10 00:35:58,595:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m 2025-07-10 00:36:00,757\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m 2025-07-10 00:36:00,757\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:36:01,502\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40f13fa0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40f13fa0>>)}\n",
      "2025-07-10 00:36:01,509\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:01,509\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m 2025-07-10 00:36:01,493\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m 2025-07-10 00:36:01,493\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m 2025-07-10 00:36:01,496\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m 2025-07-10 00:36:01,496\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m 2025-07-10 00:36:01,496\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m 2025-07-10 00:36:01,497\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m 2025-07-10 00:36:01,497\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m 2025-07-10 00:36:01,497\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2152)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:36:01,529\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:01,530\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:01,549\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:01,550\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:01,551\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:01,551\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:01,552\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:01,552\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:01,553\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:36:01,553\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:36:01,554\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:36:01,563\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:01,563\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:01,583\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:01,583\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:01,595\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:01,596\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:01,596\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:01,597\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:01,597\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:01,598\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:01,598\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:36:01,599\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:36:01,599\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:36:01,603\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40f9dfc0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40f9dfc0>>)}\n",
      "2025-07-10 00:36:01,603\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 1.\n",
      "Saving CSV for agent 1 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-58-21/policy_agent_1_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-58-21/policy_agent_1_checkpoint_5000.csv\n",
      "\n",
      "--- Training directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-30-53 ---\n",
      "Checkpoint directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-30-53/checkpoint_5000\n",
      "Config:\n",
      "NUM_ENVS: 1\n",
      "NUM_INNER_STEPS: 150\n",
      "NUM_EPOCHS: 5000\n",
      "NUM_AGENTS: 2\n",
      "SHOW_EVERY_N_EPOCHS: 1000\n",
      "SAVE_EVERY_N_EPOCHS: 500\n",
      "LR: 0.0003\n",
      "PAYOFF_MATRIX: [[1, 1, -2], [1, 1, -2]]\n",
      "GRID_SIZE: 3\n",
      "REWARD_COEF: [[0.707107, 0.707107], [1.0, 0.0]]\n",
      "SAVE_DIR: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma\n",
      "NUM_UPDATES: 4\n",
      "GAMMA: 0.9\n",
      "GAE_LAMBDA: 0.95\n",
      "ENT_COEF: 0.05\n",
      "CLIP_EPS: 0.2\n",
      "VF_COEF: 0.5\n",
      "SEED: 1\n",
      "PATH: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma/Training_2025-07-08_16-30-53\n",
      "\n",
      "Loading policy for agent 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m WARNING:2025-07-10 00:36:10,943:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m 2025-07-10 00:36:12,902\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m 2025-07-10 00:36:12,902\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:36:13,652\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40f9e890>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40f9e890>>)}\n",
      "2025-07-10 00:36:13,658\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:13,659\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:13,680\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:13,680\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m 2025-07-10 00:36:13,642\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m 2025-07-10 00:36:13,642\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m 2025-07-10 00:36:13,646\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m 2025-07-10 00:36:13,646\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m 2025-07-10 00:36:13,646\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m 2025-07-10 00:36:13,646\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m 2025-07-10 00:36:13,646\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m 2025-07-10 00:36:13,646\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2165)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:36:13,708\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:13,708\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:13,708\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:13,709\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:13,710\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:13,710\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:13,710\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:36:13,711\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:36:13,711\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:36:13,720\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:13,720\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:13,731\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:13,732\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:13,766\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:13,766\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:13,767\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:13,768\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:13,768\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:13,768\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:13,769\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:36:13,769\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:36:13,769\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:36:13,773\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe406f2ad0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe406f2ad0>>)}\n",
      "2025-07-10 00:36:13,773\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 0.\n",
      "Saving CSV for agent 0 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-30-53/policy_agent_0_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-30-53/policy_agent_0_checkpoint_5000.csv\n",
      "Loading policy for agent 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m WARNING:2025-07-10 00:36:22,556:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m 2025-07-10 00:36:24,531\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m 2025-07-10 00:36:24,531\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:36:25,254\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe406f2ce0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe406f2ce0>>)}\n",
      "2025-07-10 00:36:25,261\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:25,261\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:25,276\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:25,277\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m 2025-07-10 00:36:25,246\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m 2025-07-10 00:36:25,246\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m 2025-07-10 00:36:25,249\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m 2025-07-10 00:36:25,249\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m 2025-07-10 00:36:25,249\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m 2025-07-10 00:36:25,249\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m 2025-07-10 00:36:25,249\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m 2025-07-10 00:36:25,249\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2142)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:36:25,305\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:25,306\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:25,306\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:25,307\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:25,307\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:25,308\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:25,308\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:36:25,309\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:36:25,309\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:36:25,317\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:25,318\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:25,334\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:25,335\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:25,352\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:25,352\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:25,353\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:25,354\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:25,354\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:25,355\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:25,355\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:36:25,356\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:36:25,356\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:36:25,359\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe405f2b00>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe405f2b00>>)}\n",
      "2025-07-10 00:36:25,360\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 1.\n",
      "Saving CSV for agent 1 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-30-53/policy_agent_1_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-30-53/policy_agent_1_checkpoint_5000.csv\n",
      "\n",
      "=== Procesando REWARD_COEF=[[1.0, 0.0], [0.707, -0.707]] ===\n",
      "\n",
      "--- Training directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-31-09 ---\n",
      "Checkpoint directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-31-09/checkpoint_5000\n",
      "Config:\n",
      "NUM_ENVS: 1\n",
      "NUM_INNER_STEPS: 150\n",
      "NUM_EPOCHS: 5000\n",
      "NUM_AGENTS: 2\n",
      "SHOW_EVERY_N_EPOCHS: 1000\n",
      "SAVE_EVERY_N_EPOCHS: 500\n",
      "LR: 0.0003\n",
      "PAYOFF_MATRIX: [[1, 1, -2], [1, 1, -2]]\n",
      "GRID_SIZE: 3\n",
      "REWARD_COEF: [[1.0, 0.0], [0.707107, -0.707107]]\n",
      "SAVE_DIR: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma\n",
      "NUM_UPDATES: 4\n",
      "GAMMA: 0.9\n",
      "GAE_LAMBDA: 0.95\n",
      "ENT_COEF: 0.05\n",
      "CLIP_EPS: 0.2\n",
      "VF_COEF: 0.5\n",
      "SEED: 1\n",
      "PATH: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma/Training_2025-07-08_16-31-09\n",
      "\n",
      "Loading policy for agent 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m WARNING:2025-07-10 00:36:35,549:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m 2025-07-10 00:36:37,667\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m 2025-07-10 00:36:37,667\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:36:38,408\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe429e31f0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe429e31f0>>)}\n",
      "2025-07-10 00:36:38,415\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:38,416\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:38,435\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:38,436\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:38,451\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:38,452\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:38,452\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:38,453\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:38,453\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:38,454\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:38,454\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:36:38,454\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:36:38,455\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:36:38,464\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:38,464\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:38,483\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:38,484\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m 2025-07-10 00:36:38,398\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m 2025-07-10 00:36:38,399\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m 2025-07-10 00:36:38,402\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m 2025-07-10 00:36:38,402\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m 2025-07-10 00:36:38,402\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m 2025-07-10 00:36:38,402\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m 2025-07-10 00:36:38,402\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m 2025-07-10 00:36:38,402\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2158)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:36:38,493\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:38,493\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:38,494\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:38,495\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:38,495\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:38,496\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:38,496\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:36:38,497\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:36:38,497\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:36:38,501\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe4293a770>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe4293a770>>)}\n",
      "2025-07-10 00:36:38,501\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 0.\n",
      "Saving CSV for agent 0 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-31-09/policy_agent_0_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-31-09/policy_agent_0_checkpoint_5000.csv\n",
      "Loading policy for agent 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m WARNING:2025-07-10 00:36:48,490:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m 2025-07-10 00:36:50,463\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m 2025-07-10 00:36:50,463\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:36:51,178\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe429339d0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe429339d0>>)}\n",
      "2025-07-10 00:36:51,184\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:51,185\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m 2025-07-10 00:36:51,169\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m 2025-07-10 00:36:51,169\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m 2025-07-10 00:36:51,173\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m 2025-07-10 00:36:51,173\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m 2025-07-10 00:36:51,173\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m 2025-07-10 00:36:51,173\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m 2025-07-10 00:36:51,173\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m 2025-07-10 00:36:51,173\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2137)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:36:51,206\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:51,207\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:51,238\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:51,238\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:51,238\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:51,239\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:51,239\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:51,240\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:51,240\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:36:51,241\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:36:51,241\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:36:51,250\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:51,250\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:51,265\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:36:51,265\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:36:51,282\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:51,282\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:51,283\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:51,284\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:36:51,284\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:36:51,284\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:36:51,285\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:36:51,285\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:36:51,286\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:36:51,289\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe405f29b0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe405f29b0>>)}\n",
      "2025-07-10 00:36:51,290\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 1.\n",
      "Saving CSV for agent 1 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-31-09/policy_agent_1_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-31-09/policy_agent_1_checkpoint_5000.csv\n",
      "\n",
      "--- Training directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-34-21 ---\n",
      "Checkpoint directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-34-21/checkpoint_5000\n",
      "Config:\n",
      "NUM_ENVS: 1\n",
      "NUM_INNER_STEPS: 150\n",
      "NUM_EPOCHS: 5000\n",
      "NUM_AGENTS: 2\n",
      "SHOW_EVERY_N_EPOCHS: 1000\n",
      "SAVE_EVERY_N_EPOCHS: 500\n",
      "LR: 0.0003\n",
      "PAYOFF_MATRIX: [[1, 1, -2], [1, 1, -2]]\n",
      "GRID_SIZE: 3\n",
      "REWARD_COEF: [[1.0, 0.0], [0.707107, -0.707107]]\n",
      "SAVE_DIR: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma\n",
      "NUM_UPDATES: 4\n",
      "GAMMA: 0.9\n",
      "GAE_LAMBDA: 0.95\n",
      "ENT_COEF: 0.05\n",
      "CLIP_EPS: 0.2\n",
      "VF_COEF: 0.5\n",
      "SEED: 2\n",
      "PATH: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma/Training_2025-07-08_21-34-21\n",
      "\n",
      "Loading policy for agent 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m WARNING:2025-07-10 00:37:00,965:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m 2025-07-10 00:37:02,921\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m 2025-07-10 00:37:02,921\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:37:03,646\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbf90507160>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbf90507160>>)}\n",
      "2025-07-10 00:37:03,652\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:03,653\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m 2025-07-10 00:37:03,637\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m 2025-07-10 00:37:03,637\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m 2025-07-10 00:37:03,641\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m 2025-07-10 00:37:03,641\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m 2025-07-10 00:37:03,641\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m 2025-07-10 00:37:03,641\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m 2025-07-10 00:37:03,641\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m 2025-07-10 00:37:03,641\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2153)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:37:03,683\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:03,684\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:03,703\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:03,703\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:03,704\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:03,704\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:03,705\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:03,705\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:03,705\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:37:03,706\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:37:03,706\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:37:03,715\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:03,715\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:03,730\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:03,730\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:03,739\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:03,739\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:03,740\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:03,741\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:03,741\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:03,741\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:03,742\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:37:03,742\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:37:03,743\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:37:03,746\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe43268dc0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe43268dc0>>)}\n",
      "2025-07-10 00:37:03,747\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 0.\n",
      "Saving CSV for agent 0 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-34-21/policy_agent_0_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-34-21/policy_agent_0_checkpoint_5000.csv\n",
      "Loading policy for agent 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m WARNING:2025-07-10 00:37:13,450:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m 2025-07-10 00:37:15,439\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m 2025-07-10 00:37:15,439\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:37:16,170\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40647f40>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40647f40>>)}\n",
      "2025-07-10 00:37:16,177\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:16,177\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m 2025-07-10 00:37:16,161\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m 2025-07-10 00:37:16,161\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m 2025-07-10 00:37:16,164\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m 2025-07-10 00:37:16,164\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m 2025-07-10 00:37:16,164\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m 2025-07-10 00:37:16,165\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m 2025-07-10 00:37:16,165\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m 2025-07-10 00:37:16,165\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2166)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:37:16,198\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:16,198\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:16,215\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:16,216\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:16,216\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:16,217\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:16,217\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:16,218\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:16,218\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:37:16,218\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:37:16,219\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:37:16,227\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:16,228\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:16,244\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:16,245\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:16,260\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:16,260\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:16,261\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:16,261\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:16,262\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:16,262\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:16,262\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:37:16,263\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:37:16,263\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:37:16,267\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe41819570>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe41819570>>)}\n",
      "2025-07-10 00:37:16,268\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 1.\n",
      "Saving CSV for agent 1 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-34-21/policy_agent_1_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-34-21/policy_agent_1_checkpoint_5000.csv\n",
      "\n",
      "--- Training directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_03-04-42 ---\n",
      "Checkpoint directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_03-04-42/checkpoint_5000\n",
      "Config:\n",
      "NUM_ENVS: 1\n",
      "NUM_INNER_STEPS: 150\n",
      "NUM_EPOCHS: 5000\n",
      "NUM_AGENTS: 2\n",
      "SHOW_EVERY_N_EPOCHS: 1000\n",
      "SAVE_EVERY_N_EPOCHS: 500\n",
      "LR: 0.0003\n",
      "PAYOFF_MATRIX: [[1, 1, -2], [1, 1, -2]]\n",
      "GRID_SIZE: 3\n",
      "REWARD_COEF: [[1.0, 0.0], [0.707107, -0.707107]]\n",
      "SAVE_DIR: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma\n",
      "NUM_UPDATES: 4\n",
      "GAMMA: 0.9\n",
      "GAE_LAMBDA: 0.95\n",
      "ENT_COEF: 0.05\n",
      "CLIP_EPS: 0.2\n",
      "VF_COEF: 0.5\n",
      "SEED: 3\n",
      "PATH: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma/Training_2025-07-09_03-04-42\n",
      "\n",
      "Loading policy for agent 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m WARNING:2025-07-10 00:37:26,042:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m 2025-07-10 00:37:27,996\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m 2025-07-10 00:37:27,996\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:37:28,714\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe42948ee0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe42948ee0>>)}\n",
      "2025-07-10 00:37:28,720\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:28,720\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:28,740\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:28,740\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:28,769\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:28,770\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:28,770\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:28,771\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:28,771\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:28,772\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:28,772\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:37:28,773\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:37:28,773\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m 2025-07-10 00:37:28,705\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m 2025-07-10 00:37:28,705\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m 2025-07-10 00:37:28,708\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m 2025-07-10 00:37:28,708\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m 2025-07-10 00:37:28,708\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m 2025-07-10 00:37:28,708\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m 2025-07-10 00:37:28,708\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m 2025-07-10 00:37:28,708\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2134)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:37:28,782\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:28,783\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:28,795\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:28,796\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:28,813\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:28,814\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:28,814\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:28,815\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:28,815\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:28,816\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:28,816\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:37:28,816\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:37:28,817\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:37:28,820\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40476c50>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40476c50>>)}\n",
      "2025-07-10 00:37:28,821\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 0.\n",
      "Saving CSV for agent 0 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_03-04-42/policy_agent_0_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_03-04-42/policy_agent_0_checkpoint_5000.csv\n",
      "Loading policy for agent 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m WARNING:2025-07-10 00:37:38,464:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m 2025-07-10 00:37:40,470\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m 2025-07-10 00:37:40,470\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:37:41,211\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe41841900>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe41841900>>)}\n",
      "2025-07-10 00:37:41,217\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:41,218\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:41,254\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:41,254\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m 2025-07-10 00:37:41,202\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m 2025-07-10 00:37:41,202\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m 2025-07-10 00:37:41,205\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m 2025-07-10 00:37:41,205\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m 2025-07-10 00:37:41,205\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m 2025-07-10 00:37:41,205\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m 2025-07-10 00:37:41,205\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m 2025-07-10 00:37:41,206\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=2133)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:37:41,276\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:41,276\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:41,277\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:41,277\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:41,278\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:41,278\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:41,279\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:37:41,280\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:37:41,280\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:37:41,289\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:41,290\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:41,304\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:41,304\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:41,313\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:41,313\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:41,314\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:41,315\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:41,315\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:41,315\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:41,316\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:37:41,316\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:37:41,317\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:37:41,320\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe4032ef50>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe4032ef50>>)}\n",
      "2025-07-10 00:37:41,321\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 1.\n",
      "Saving CSV for agent 1 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_03-04-42/policy_agent_1_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_03-04-42/policy_agent_1_checkpoint_5000.csv\n",
      "\n",
      "=== Procesando REWARD_COEF=[[0.707, -0.707], [1.0, 0.0]] ===\n",
      "\n",
      "--- Training directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-57-55 ---\n",
      "Checkpoint directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-57-55/checkpoint_5000\n",
      "Config:\n",
      "NUM_ENVS: 1\n",
      "NUM_INNER_STEPS: 150\n",
      "NUM_EPOCHS: 5000\n",
      "NUM_AGENTS: 2\n",
      "SHOW_EVERY_N_EPOCHS: 1000\n",
      "SAVE_EVERY_N_EPOCHS: 500\n",
      "LR: 0.0003\n",
      "PAYOFF_MATRIX: [[1, 1, -2], [1, 1, -2]]\n",
      "GRID_SIZE: 3\n",
      "REWARD_COEF: [[0.707107, -0.707107], [1.0, 0.0]]\n",
      "SAVE_DIR: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma\n",
      "NUM_UPDATES: 4\n",
      "GAMMA: 0.9\n",
      "GAE_LAMBDA: 0.95\n",
      "ENT_COEF: 0.05\n",
      "CLIP_EPS: 0.2\n",
      "VF_COEF: 0.5\n",
      "SEED: 3\n",
      "PATH: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma/Training_2025-07-09_02-57-55\n",
      "\n",
      "Loading policy for agent 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m WARNING:2025-07-10 00:37:51,328:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m 2025-07-10 00:37:53,352\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m 2025-07-10 00:37:53,352\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m 2025-07-10 00:37:54,077\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m 2025-07-10 00:37:54,077\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m 2025-07-10 00:37:54,081\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m 2025-07-10 00:37:54,081\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m 2025-07-10 00:37:54,081\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m 2025-07-10 00:37:54,081\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m 2025-07-10 00:37:54,081\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m 2025-07-10 00:37:54,081\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3388)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:37:54,087\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe403c7940>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe403c7940>>)}\n",
      "2025-07-10 00:37:54,093\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:54,094\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:54,122\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:54,122\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:54,157\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:54,157\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:54,157\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:54,159\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:54,159\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:54,159\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:54,160\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:37:54,160\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:37:54,162\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:37:54,171\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:54,172\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:54,183\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:37:54,183\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:37:54,197\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:54,198\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:54,198\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:54,199\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:37:54,200\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:37:54,200\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:37:54,200\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:37:54,201\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:37:54,201\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:37:54,204\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40243220>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40243220>>)}\n",
      "2025-07-10 00:37:54,205\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 0.\n",
      "Saving CSV for agent 0 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-57-55/policy_agent_0_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-57-55/policy_agent_0_checkpoint_5000.csv\n",
      "Loading policy for agent 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m WARNING:2025-07-10 00:38:04,095:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m 2025-07-10 00:38:06,008\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m 2025-07-10 00:38:06,008\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:38:06,736\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe403c6b90>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe403c6b90>>)}\n",
      "2025-07-10 00:38:06,743\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:06,743\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:06,770\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:06,771\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:06,786\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:06,786\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:06,787\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:06,787\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:06,788\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m 2025-07-10 00:38:06,727\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m 2025-07-10 00:38:06,728\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m 2025-07-10 00:38:06,731\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m 2025-07-10 00:38:06,731\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m 2025-07-10 00:38:06,731\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m 2025-07-10 00:38:06,731\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m 2025-07-10 00:38:06,731\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m 2025-07-10 00:38:06,731\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3484)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:38:06,789\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:06,789\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:38:06,789\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:38:06,790\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:38:06,798\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:06,798\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:06,811\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:06,812\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:06,823\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:06,823\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:06,824\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:06,825\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:06,826\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:06,826\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:06,827\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:38:06,827\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:38:06,827\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:38:06,831\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe4017f8b0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe4017f8b0>>)}\n",
      "2025-07-10 00:38:06,831\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 1.\n",
      "Saving CSV for agent 1 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-57-55/policy_agent_1_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-57-55/policy_agent_1_checkpoint_5000.csv\n",
      "\n",
      "--- Training directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-31-22 ---\n",
      "Checkpoint directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-31-22/checkpoint_5000\n",
      "Config:\n",
      "NUM_ENVS: 1\n",
      "NUM_INNER_STEPS: 150\n",
      "NUM_EPOCHS: 5000\n",
      "NUM_AGENTS: 2\n",
      "SHOW_EVERY_N_EPOCHS: 1000\n",
      "SAVE_EVERY_N_EPOCHS: 500\n",
      "LR: 0.0003\n",
      "PAYOFF_MATRIX: [[1, 1, -2], [1, 1, -2]]\n",
      "GRID_SIZE: 3\n",
      "REWARD_COEF: [[0.707107, -0.707107], [1.0, 0.0]]\n",
      "SAVE_DIR: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma\n",
      "NUM_UPDATES: 4\n",
      "GAMMA: 0.9\n",
      "GAE_LAMBDA: 0.95\n",
      "ENT_COEF: 0.05\n",
      "CLIP_EPS: 0.2\n",
      "VF_COEF: 0.5\n",
      "SEED: 1\n",
      "PATH: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma/Training_2025-07-08_16-31-22\n",
      "\n",
      "Loading policy for agent 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m WARNING:2025-07-10 00:38:16,421:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m 2025-07-10 00:38:18,389\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m 2025-07-10 00:38:18,389\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:38:19,116\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40009c30>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe40009c30>>)}\n",
      "2025-07-10 00:38:19,122\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:19,123\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:19,139\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:19,139\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:19,152\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:19,152\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:19,153\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:19,154\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:19,154\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:19,155\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:19,155\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:38:19,156\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:38:19,156\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:38:19,164\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:19,165\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:19,179\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:19,179\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:19,191\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:19,192\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:19,192\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:19,193\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:19,193\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:19,194\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:19,194\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:38:19,195\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:38:19,195\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:38:19,199\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe400aab60>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe400aab60>>)}\n",
      "2025-07-10 00:38:19,200\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m 2025-07-10 00:38:19,106\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m 2025-07-10 00:38:19,107\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m 2025-07-10 00:38:19,110\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m 2025-07-10 00:38:19,110\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m 2025-07-10 00:38:19,110\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m 2025-07-10 00:38:19,110\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m 2025-07-10 00:38:19,110\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m 2025-07-10 00:38:19,110\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3590)\u001b[0m         ImmutableActionsConnector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 0.\n",
      "Saving CSV for agent 0 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-31-22/policy_agent_0_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-31-22/policy_agent_0_checkpoint_5000.csv\n",
      "Loading policy for agent 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m WARNING:2025-07-10 00:38:28,819:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m 2025-07-10 00:38:30,759\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m 2025-07-10 00:38:30,759\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m 2025-07-10 00:38:31,500\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m 2025-07-10 00:38:31,501\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m 2025-07-10 00:38:31,505\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m 2025-07-10 00:38:31,505\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m 2025-07-10 00:38:31,505\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m 2025-07-10 00:38:31,505\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m 2025-07-10 00:38:31,505\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m 2025-07-10 00:38:31,505\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3682)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:38:31,511\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe30728fd0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe30728fd0>>)}\n",
      "2025-07-10 00:38:31,518\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:31,518\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:31,546\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:31,547\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:31,559\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:31,559\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:31,560\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:31,561\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:31,561\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:31,561\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:31,562\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:38:31,562\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:38:31,562\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:38:31,571\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:31,572\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:31,583\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:31,584\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:31,598\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:31,598\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:31,599\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:31,599\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:31,600\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:31,600\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:31,600\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:38:31,601\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:38:31,601\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:38:31,605\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe307d39a0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe307d39a0>>)}\n",
      "2025-07-10 00:38:31,605\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 1.\n",
      "Saving CSV for agent 1 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-31-22/policy_agent_1_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-31-22/policy_agent_1_checkpoint_5000.csv\n",
      "\n",
      "--- Training directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-28-27 ---\n",
      "Checkpoint directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-28-27/checkpoint_5000\n",
      "Config:\n",
      "NUM_ENVS: 1\n",
      "NUM_INNER_STEPS: 150\n",
      "NUM_EPOCHS: 5000\n",
      "NUM_AGENTS: 2\n",
      "SHOW_EVERY_N_EPOCHS: 1000\n",
      "SAVE_EVERY_N_EPOCHS: 500\n",
      "LR: 0.0003\n",
      "PAYOFF_MATRIX: [[1, 1, -2], [1, 1, -2]]\n",
      "GRID_SIZE: 3\n",
      "REWARD_COEF: [[0.707107, -0.707107], [1.0, 0.0]]\n",
      "SAVE_DIR: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma\n",
      "NUM_UPDATES: 4\n",
      "GAMMA: 0.9\n",
      "GAE_LAMBDA: 0.95\n",
      "ENT_COEF: 0.05\n",
      "CLIP_EPS: 0.2\n",
      "VF_COEF: 0.5\n",
      "SEED: 2\n",
      "PATH: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma/Training_2025-07-08_21-28-27\n",
      "\n",
      "Loading policy for agent 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m WARNING:2025-07-10 00:38:41,480:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m 2025-07-10 00:38:43,430\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m 2025-07-10 00:38:43,430\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:38:44,145\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe3065f1f0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe3065f1f0>>)}\n",
      "2025-07-10 00:38:44,151\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:44,152\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:44,184\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:44,184\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:44,210\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:44,210\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:44,211\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:44,211\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:44,212\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:44,212\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:44,213\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:38:44,213\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:38:44,214\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m 2025-07-10 00:38:44,136\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m 2025-07-10 00:38:44,136\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m 2025-07-10 00:38:44,139\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m 2025-07-10 00:38:44,139\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m 2025-07-10 00:38:44,139\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m 2025-07-10 00:38:44,139\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m 2025-07-10 00:38:44,139\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m 2025-07-10 00:38:44,139\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3774)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:38:44,223\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:44,224\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:44,242\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:44,243\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:44,252\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:44,252\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:44,253\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:44,254\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:44,254\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:44,254\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:44,255\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:38:44,255\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:38:44,256\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:38:44,259\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe304ffc40>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe304ffc40>>)}\n",
      "2025-07-10 00:38:44,259\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 0.\n",
      "Saving CSV for agent 0 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-28-27/policy_agent_0_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-28-27/policy_agent_0_checkpoint_5000.csv\n",
      "Loading policy for agent 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m WARNING:2025-07-10 00:38:54,706:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m 2025-07-10 00:38:56,981\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m 2025-07-10 00:38:56,981\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:38:57,728\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe3050b6d0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe3050b6d0>>)}\n",
      "2025-07-10 00:38:57,735\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:57,736\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m 2025-07-10 00:38:57,718\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m 2025-07-10 00:38:57,718\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m 2025-07-10 00:38:57,722\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m 2025-07-10 00:38:57,722\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m 2025-07-10 00:38:57,722\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m 2025-07-10 00:38:57,723\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m 2025-07-10 00:38:57,723\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m 2025-07-10 00:38:57,723\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3868)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:38:57,761\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:57,762\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:57,784\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:57,785\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:57,785\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:57,786\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:57,786\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:57,787\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:57,787\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:38:57,787\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:38:57,788\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:38:57,797\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:57,797\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:57,822\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:38:57,823\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:38:57,846\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:57,847\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:57,847\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:57,848\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:38:57,849\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:38:57,849\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:38:57,850\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:38:57,850\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:38:57,851\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:38:57,855\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe3043b9d0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe3043b9d0>>)}\n",
      "2025-07-10 00:38:57,856\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 1.\n",
      "Saving CSV for agent 1 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-28-27/policy_agent_1_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-28-27/policy_agent_1_checkpoint_5000.csv\n",
      "\n",
      "=== Procesando REWARD_COEF=[[1.0, 0.0], [0.707, 0.707]] ===\n",
      "\n",
      "--- Training directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-26-10 ---\n",
      "Checkpoint directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-26-10/checkpoint_5000\n",
      "Config:\n",
      "NUM_ENVS: 1\n",
      "NUM_INNER_STEPS: 150\n",
      "NUM_EPOCHS: 5000\n",
      "NUM_AGENTS: 2\n",
      "SHOW_EVERY_N_EPOCHS: 1000\n",
      "SAVE_EVERY_N_EPOCHS: 500\n",
      "LR: 0.0003\n",
      "PAYOFF_MATRIX: [[1, 1, -2], [1, 1, -2]]\n",
      "GRID_SIZE: 3\n",
      "REWARD_COEF: [[1.0, 0.0], [0.707107, 0.707107]]\n",
      "SAVE_DIR: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma\n",
      "NUM_UPDATES: 4\n",
      "GAMMA: 0.9\n",
      "GAE_LAMBDA: 0.95\n",
      "ENT_COEF: 0.05\n",
      "CLIP_EPS: 0.2\n",
      "VF_COEF: 0.5\n",
      "SEED: 2\n",
      "PATH: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma/Training_2025-07-08_21-26-10\n",
      "\n",
      "Loading policy for agent 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m WARNING:2025-07-10 00:39:09,302:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m 2025-07-10 00:39:11,530\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m 2025-07-10 00:39:11,531\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m 2025-07-10 00:39:12,293\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m 2025-07-10 00:39:12,293\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m 2025-07-10 00:39:12,297\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m 2025-07-10 00:39:12,297\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m 2025-07-10 00:39:12,297\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m 2025-07-10 00:39:12,297\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m 2025-07-10 00:39:12,297\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m 2025-07-10 00:39:12,297\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=3962)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:39:12,303\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe305b9990>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe305b9990>>)}\n",
      "2025-07-10 00:39:12,312\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:12,312\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:12,346\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:12,346\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:12,379\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:12,380\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:12,381\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:12,381\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:12,382\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:12,382\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:12,383\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:39:12,383\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:39:12,384\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:39:12,397\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:12,397\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:12,431\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:12,432\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:12,444\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:12,445\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:12,445\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:12,447\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:12,448\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:12,448\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:12,449\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:39:12,449\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:39:12,451\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:39:12,455\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe303e8250>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe303e8250>>)}\n",
      "2025-07-10 00:39:12,456\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 0.\n",
      "Saving CSV for agent 0 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-26-10/policy_agent_0_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-26-10/policy_agent_0_checkpoint_5000.csv\n",
      "Loading policy for agent 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m WARNING:2025-07-10 00:39:23,317:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m 2025-07-10 00:39:25,485\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m 2025-07-10 00:39:25,485\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:39:26,337\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe303ebd30>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe303ebd30>>)}\n",
      "2025-07-10 00:39:26,345\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:26,346\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m 2025-07-10 00:39:26,325\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m 2025-07-10 00:39:26,326\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m 2025-07-10 00:39:26,330\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m 2025-07-10 00:39:26,330\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m 2025-07-10 00:39:26,330\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m 2025-07-10 00:39:26,330\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m 2025-07-10 00:39:26,330\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m 2025-07-10 00:39:26,330\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4065)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:39:26,368\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:26,369\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:26,393\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:26,394\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:26,394\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:26,395\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:26,396\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:26,396\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:26,397\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:39:26,398\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:39:26,398\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:39:26,407\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:26,408\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:26,420\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:26,421\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:26,434\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:26,435\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:26,436\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:26,438\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:26,438\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:26,439\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:26,440\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:39:26,440\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:39:26,441\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:39:26,446\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe301202e0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe301202e0>>)}\n",
      "2025-07-10 00:39:26,447\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 1.\n",
      "Saving CSV for agent 1 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-26-10/policy_agent_1_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_21-26-10/policy_agent_1_checkpoint_5000.csv\n",
      "\n",
      "--- Training directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-56-48 ---\n",
      "Checkpoint directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-56-48/checkpoint_5000\n",
      "Config:\n",
      "NUM_ENVS: 1\n",
      "NUM_INNER_STEPS: 150\n",
      "NUM_EPOCHS: 5000\n",
      "NUM_AGENTS: 2\n",
      "SHOW_EVERY_N_EPOCHS: 1000\n",
      "SAVE_EVERY_N_EPOCHS: 500\n",
      "LR: 0.0003\n",
      "PAYOFF_MATRIX: [[1, 1, -2], [1, 1, -2]]\n",
      "GRID_SIZE: 3\n",
      "REWARD_COEF: [[1.0, 0.0], [0.707107, 0.707107]]\n",
      "SAVE_DIR: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma\n",
      "NUM_UPDATES: 4\n",
      "GAMMA: 0.9\n",
      "GAE_LAMBDA: 0.95\n",
      "ENT_COEF: 0.05\n",
      "CLIP_EPS: 0.2\n",
      "VF_COEF: 0.5\n",
      "SEED: 3\n",
      "PATH: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma/Training_2025-07-09_02-56-48\n",
      "\n",
      "Loading policy for agent 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m WARNING:2025-07-10 00:39:37,013:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m 2025-07-10 00:39:38,959\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m 2025-07-10 00:39:38,959\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m 2025-07-10 00:39:39,689\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m 2025-07-10 00:39:39,689\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m 2025-07-10 00:39:39,693\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m 2025-07-10 00:39:39,693\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m 2025-07-10 00:39:39,693\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m 2025-07-10 00:39:39,693\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m 2025-07-10 00:39:39,693\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m 2025-07-10 00:39:39,693\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4157)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:39:39,699\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe301209a0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe301209a0>>)}\n",
      "2025-07-10 00:39:39,705\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:39,706\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:39,732\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:39,733\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:39,769\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:39,770\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:39,770\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:39,772\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:39,772\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:39,772\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:39,773\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:39:39,773\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:39:39,773\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:39:39,782\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:39,782\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:39,793\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:39,794\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:39,811\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:39,812\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:39,812\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:39,813\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:39,813\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:39,814\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:39,814\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:39:39,815\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:39:39,815\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:39:39,818\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe1e73c580>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe1e73c580>>)}\n",
      "2025-07-10 00:39:39,819\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 0.\n",
      "Saving CSV for agent 0 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-56-48/policy_agent_0_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-56-48/policy_agent_0_checkpoint_5000.csv\n",
      "Loading policy for agent 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m WARNING:2025-07-10 00:39:49,879:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m 2025-07-10 00:39:52,017\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m 2025-07-10 00:39:52,017\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:39:52,774\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe3021a110>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe3021a110>>)}\n",
      "2025-07-10 00:39:52,780\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:52,781\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:52,802\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:52,803\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:52,820\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:52,821\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:52,822\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:52,822\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:52,823\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:52,823\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:52,823\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:39:52,824\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:39:52,824\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:39:52,834\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:52,834\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m 2025-07-10 00:39:52,764\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m 2025-07-10 00:39:52,764\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m 2025-07-10 00:39:52,768\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m 2025-07-10 00:39:52,768\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m 2025-07-10 00:39:52,768\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m 2025-07-10 00:39:52,768\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m 2025-07-10 00:39:52,768\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m 2025-07-10 00:39:52,768\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4251)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:39:52,851\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:39:52,852\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:39:52,860\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:52,860\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:52,861\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:52,861\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:39:52,862\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:39:52,862\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:39:52,864\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:39:52,864\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:39:52,865\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:39:52,868\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe1d668760>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe1d668760>>)}\n",
      "2025-07-10 00:39:52,869\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 1.\n",
      "Saving CSV for agent 1 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-56-48/policy_agent_1_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-09_02-56-48/policy_agent_1_checkpoint_5000.csv\n",
      "\n",
      "--- Training directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-26-49 ---\n",
      "Checkpoint directory: /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-26-49/checkpoint_5000\n",
      "Config:\n",
      "NUM_ENVS: 1\n",
      "NUM_INNER_STEPS: 150\n",
      "NUM_EPOCHS: 5000\n",
      "NUM_AGENTS: 2\n",
      "SHOW_EVERY_N_EPOCHS: 1000\n",
      "SAVE_EVERY_N_EPOCHS: 500\n",
      "LR: 0.0003\n",
      "PAYOFF_MATRIX: [[1, 1, -2], [1, 1, -2]]\n",
      "GRID_SIZE: 3\n",
      "REWARD_COEF: [[1.0, 0.0], [0.707107, 0.707107]]\n",
      "SAVE_DIR: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma\n",
      "NUM_UPDATES: 4\n",
      "GAMMA: 0.9\n",
      "GAE_LAMBDA: 0.95\n",
      "ENT_COEF: 0.05\n",
      "CLIP_EPS: 0.2\n",
      "VF_COEF: 0.5\n",
      "SEED: 1\n",
      "PATH: /data/samuel_lozano/CoopCoins/RLLIB/No_dilemma/Training_2025-07-08_16-26-49\n",
      "\n",
      "Loading policy for agent 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m WARNING:2025-07-10 00:40:03,181:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m 2025-07-10 00:40:05,485\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m 2025-07-10 00:40:05,485\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:40:06,245\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe1d668640>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe1d668640>>)}\n",
      "2025-07-10 00:40:06,251\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:40:06,252\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:40:06,279\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:40:06,279\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m 2025-07-10 00:40:06,236\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m 2025-07-10 00:40:06,236\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m 2025-07-10 00:40:06,239\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m 2025-07-10 00:40:06,239\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m 2025-07-10 00:40:06,239\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m 2025-07-10 00:40:06,239\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m 2025-07-10 00:40:06,240\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m 2025-07-10 00:40:06,240\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4346)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:40:06,310\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:40:06,311\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:40:06,311\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:40:06,312\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:40:06,312\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:40:06,313\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:40:06,313\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:40:06,313\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:40:06,314\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:40:06,323\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:40:06,323\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:40:06,338\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:40:06,338\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:40:06,356\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:40:06,356\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:40:06,357\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:40:06,357\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:40:06,358\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:40:06,358\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:40:06,359\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:40:06,360\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:40:06,361\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:40:06,364\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe1c598a00>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe1c598a00>>)}\n",
      "2025-07-10 00:40:06,365\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 0.\n",
      "Saving CSV for agent 0 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-26-49/policy_agent_0_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-26-49/policy_agent_0_checkpoint_5000.csv\n",
      "Loading policy for agent 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/samuel_lozano/miniconda3/envs/JaxMARL_TFM/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m WARNING:2025-07-10 00:40:16,623:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m 2025-07-10 00:40:18,559\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m 2025-07-10 00:40:18,559\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "2025-07-10 00:40:19,290\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe1c59b370>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe1c59b370>>)}\n",
      "2025-07-10 00:40:19,297\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:40:19,298\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:40:19,314\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:40:19,314\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m 2025-07-10 00:40:19,281\tINFO policy.py:1234 -- Policy (worker=1) running on CPU.\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m 2025-07-10 00:40:19,281\tINFO torch_policy_v2.py:105 -- Found 0 visible cuda devices.\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m 2025-07-10 00:40:19,284\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m 2025-07-10 00:40:19,284\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m 2025-07-10 00:40:19,284\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m         ImmutableActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m 2025-07-10 00:40:19,285\tINFO util.py:118 -- Using connectors:\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m 2025-07-10 00:40:19,285\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m         ObsPreprocessorConnector\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m         StateBufferConnector\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m         ViewRequirementAgentConnector\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m 2025-07-10 00:40:19,285\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m         ConvertToNumpyConnector\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m         NormalizeActionsConnector\n",
      "\u001b[36m(RolloutWorker pid=4438)\u001b[0m         ImmutableActionsConnector\n",
      "2025-07-10 00:40:19,338\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:40:19,339\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:40:19,339\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:40:19,340\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:40:19,341\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:40:19,341\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:40:19,342\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:40:19,342\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:40:19,343\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:40:19,352\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:40:19,353\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:40:19,374\tINFO policy.py:1234 -- Policy (worker=local) running on 0.25 GPUs.\n",
      "2025-07-10 00:40:19,374\tINFO torch_policy_v2.py:105 -- Found 1 visible cuda devices.\n",
      "2025-07-10 00:40:19,389\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:40:19,390\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:40:19,390\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:40:19,391\tINFO util.py:118 -- Using connectors:\n",
      "2025-07-10 00:40:19,391\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2025-07-10 00:40:19,391\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2025-07-10 00:40:19,392\tINFO rollout_worker.py:1742 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['agent_0', 'agent_1']>\n",
      "2025-07-10 00:40:19,393\tINFO rollout_worker.py:1743 -- Built preprocessor map: {'agent_0': None, 'agent_1': None}\n",
      "2025-07-10 00:40:19,393\tINFO rollout_worker.py:542 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2025-07-10 00:40:19,396\tINFO env_runner_group.py:320 -- Inferred observation/action spaces from remote worker (local worker has no env): {'agent_0': (Box(0, 1, (36,), uint8), Discrete(5)), 'agent_1': (Box(0, 1, (36,), uint8), Discrete(5)), '__env__': (<bound method CoinGameRLLibEnv.observation_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe1b4ccbe0>>, <bound method CoinGameRLLibEnv.action_space of <jaxmarl.environments.coin_game.coin_game_rllib_env.CoinGameRLLibEnv object at 0x7fbe1b4ccbe0>>)}\n",
      "2025-07-10 00:40:19,397\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy loaded for agent 1.\n",
      "Saving CSV for agent 1 to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-26-49/policy_agent_1_checkpoint_5000.csv...\n",
      "CSV saved at /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/No_dilemma/Training_2025-07-08_16-26-49/policy_agent_1_checkpoint_5000.csv\n"
     ]
    }
   ],
   "source": [
    "for coef, dir_paths in matches.items():\n",
    "    print(f\"\\n=== Procesando REWARD_COEF={coef} ===\")\n",
    "    for dir_path in dir_paths:\n",
    "        print(f\"\\n--- Training directory: {dir_path} ---\")\n",
    "        checkpoint_dir = os.path.join(dir_path, f'checkpoint_{CHECKPOINT}')\n",
    "        print(f\"Checkpoint directory: {checkpoint_dir}\")\n",
    "        config_path = os.path.join(dir_path, 'config.txt')\n",
    "        if os.path.exists(config_path):\n",
    "            with open(config_path) as f:\n",
    "                print(\"Config:\")\n",
    "                print(f.read())\n",
    "        else:\n",
    "            print(\"Config file not found.\")\n",
    "\n",
    "        try:\n",
    "            for agent_id in [0, 1]:\n",
    "                print(f\"Loading policy for agent {agent_id}...\")\n",
    "                policy = load_policy(dir_path, agent_id)\n",
    "                print(f\"Policy loaded for agent {agent_id}.\")\n",
    "                output_csv = f\"policy_agent_{agent_id}_checkpoint_{CHECKPOINT}.csv\"\n",
    "                output_path = os.path.join(dir_path, output_csv)\n",
    "                print(f\"Saving CSV for agent {agent_id} to {output_path}...\")\n",
    "                extract_policy_to_csv(policy, output_path, agent_id, grid_size=3)\n",
    "                print(f\"CSV saved at {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading policy or saving CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved as /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/all_policies_combined.csv\n"
     ]
    }
   ],
   "source": [
    "all_rows = []\n",
    "\n",
    "for coef, dir_paths in matches.items():\n",
    "    for dir_path in dir_paths:\n",
    "        config_path = os.path.join(dir_path, 'config.txt')\n",
    "        if not os.path.exists(config_path):\n",
    "            print(f\"Config file not found in {dir_path}\")\n",
    "            continue\n",
    "\n",
    "        # Parse config.txt\n",
    "        with open(config_path) as f:\n",
    "            config_lines = f.readlines()\n",
    "        config_dict = {}\n",
    "        for line in config_lines:\n",
    "            if ':' in line:\n",
    "                key, value = line.split(':', 1)\n",
    "                config_dict[key.strip()] = value.strip()\n",
    "        try:\n",
    "            lr = float(config_dict.get('LR', 'nan'))\n",
    "            seed = int(config_dict.get('SEED', 'nan'))\n",
    "            reward_coef = eval(config_dict.get('REWARD_COEF', '[[nan, nan], [nan, nan]]'))\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing config in {dir_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for agent_id in [0, 1]:\n",
    "            csv_file = os.path.join(dir_path, f'policy_agent_{agent_id}_checkpoint_{CHECKPOINT}.csv')\n",
    "            if not os.path.exists(csv_file):\n",
    "                print(f\"CSV not found: {csv_file}\")\n",
    "                continue\n",
    "\n",
    "            # Parse checkpoint from filename\n",
    "            m = re.search(r'checkpoint_(\\d+)', csv_file)\n",
    "            checkpoint_num = int(m.group(1)) if m else None\n",
    "\n",
    "            # Set own and other reward coefs\n",
    "            own_coef = reward_coef[agent_id]\n",
    "            other_coef = reward_coef[1 - agent_id]\n",
    "\n",
    "            # Read policy CSV\n",
    "            df = pd.read_csv(csv_file)\n",
    "            # Add columns at the beginning\n",
    "            df.insert(0, 'DILEMMA', DILEMMA)\n",
    "            df.insert(1, 'LR', lr)\n",
    "            df.insert(2, 'SEED', seed)\n",
    "            df.insert(3, 'CHECKPOINT', checkpoint_num)\n",
    "            df.insert(4, 'OWN_REWARD_COEF_ALPHA', own_coef[0])\n",
    "            df.insert(5, 'OWN_REWARD_COEF_BETA', own_coef[1])\n",
    "            df.insert(6, 'OTHER_REWARD_COEF_ALPHA', other_coef[0])\n",
    "            df.insert(7, 'OTHER_REWARD_COEF_BETA', other_coef[1])\n",
    "            df.insert(8, 'AGENT_ID', agent_id)\n",
    "            #df.insert(9, 'DIR_PATH', dir_path)\n",
    "            all_rows.append(df)\n",
    "\n",
    "# Concatenate all\n",
    "if all_rows:\n",
    "    final_df = pd.concat(all_rows, ignore_index=True)\n",
    "    output_csv_path = os.path.join(MAIN_PATH, \"all_policies_combined.csv\")\n",
    "    final_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Combined CSV saved as {output_csv_path}\")\n",
    "else:\n",
    "    print(\"No data found to combine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANY GAMES DECISION COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = find_training_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_dir = os.path.join(MAIN_PATH, \"comparing_policies\")\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "\n",
    "def save_plot(fig, name, dir):\n",
    "    fig_path = os.path.join(dir, name)\n",
    "    fig.savefig(fig_path)\n",
    "    plt.close(fig)\n",
    "    print(f\"Figure saved to {fig_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_5 = [\n",
    "    'own_coin_collected',\n",
    "    'other_coin_collected',\n",
    "    'reject_own_coin',\n",
    "    'reject_other_coin',\n",
    "    'no_coin_visible'\n",
    "]\n",
    "categories_2 = [\n",
    "    'own_coin_collected',\n",
    "    'other_coin_collected'\n",
    "]\n",
    "action_labels = ['right', 'left', 'up', 'down', 'stay']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group directories by seed\n",
    "seed_to_dirs = {}\n",
    "\n",
    "for coef, dir_paths in matches.items():\n",
    "    for dir_path in dir_paths:\n",
    "        config_path = os.path.join(dir_path, 'config.txt')\n",
    "        if not os.path.exists(config_path):\n",
    "            continue\n",
    "        with open(config_path) as f:\n",
    "            config_lines = f.readlines()\n",
    "        config_dict = {}\n",
    "        for line in config_lines:\n",
    "            if ':' in line:\n",
    "                key, value = line.split(':', 1)\n",
    "                config_dict[key.strip()] = value.strip()\n",
    "        try:\n",
    "            seed = int(config_dict.get('SEED', 'nan'))\n",
    "        except Exception:\n",
    "            continue\n",
    "        if seed not in seed_to_dirs:\n",
    "            seed_to_dirs[seed] = []\n",
    "        seed_to_dirs[seed].append((dir_path, coef, config_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_histograms_seed_2_Training_2025-07-08_21-32-43.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_histograms_seed_2_Training_2025-07-08_21-34-21.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_histograms_seed_2_Training_2025-07-08_21-28-27.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_histograms_seed_2_Training_2025-07-08_21-26-10.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_histograms_seed_3_Training_2025-07-09_02-58-21.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_histograms_seed_3_Training_2025-07-09_03-04-42.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_histograms_seed_3_Training_2025-07-09_02-57-55.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_histograms_seed_3_Training_2025-07-09_02-56-48.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_histograms_seed_1_Training_2025-07-08_16-30-53.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_histograms_seed_1_Training_2025-07-08_16-31-09.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_histograms_seed_1_Training_2025-07-08_16-31-22.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_histograms_seed_1_Training_2025-07-08_16-26-49.png\n"
     ]
    }
   ],
   "source": [
    "for seed, dir_info_list in seed_to_dirs.items():\n",
    "    for dir_path, coef, config_dict in dir_info_list:\n",
    "        csv_agent_0 = os.path.join(dir_path, f'policy_agent_0_checkpoint_{CHECKPOINT}.csv')\n",
    "        csv_agent_1 = os.path.join(dir_path, f'policy_agent_1_checkpoint_{CHECKPOINT}.csv')\n",
    "\n",
    "        if not (os.path.exists(csv_agent_0) and os.path.exists(csv_agent_1)):\n",
    "            print(f\"CSV files not found for SEED={seed} in {dir_path}\")\n",
    "            continue\n",
    "\n",
    "        df0 = pd.read_csv(csv_agent_0)\n",
    "        df1 = pd.read_csv(csv_agent_1)\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        # Compose important info for the title\n",
    "        lr = config_dict.get('LR', 'N/A')\n",
    "        reward_coef = config_dict.get('REWARD_COEF', 'N/A')\n",
    "        title = (f\"Policy Histograms for SEED={seed}\\n\"\n",
    "                 f\"LR={lr}, REWARD_COEF={reward_coef}\\n\"\n",
    "                 f\"Dir: {os.path.basename(dir_path)}\")\n",
    "        plt.suptitle(title, fontsize=14)\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(df0['action'].dropna(), bins=range(6), align='left', rwidth=0.8, color='blue')\n",
    "        plt.title('Agent 0 Policy Histogram')\n",
    "        plt.xlabel('Action')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(range(5), ['right', 'left', 'up', 'down', 'stay'])\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(df1['action'].dropna(), bins=range(6), align='left', rwidth=0.8, color='red')\n",
    "        plt.title('Agent 1 Policy Histogram')\n",
    "        plt.xlabel('Action')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(range(5), ['right', 'left', 'up', 'down', 'stay'])\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.08, 1, 0.95])\n",
    "\n",
    "        # Save with seed and dir name in filename\n",
    "        safe_dir = os.path.basename(dir_path).replace(' ', '_')\n",
    "        fig_path = os.path.join(figures_dir, f'policy_histograms_seed_{seed}_{safe_dir}.png')\n",
    "        plt.savefig(fig_path)\n",
    "        plt.close()\n",
    "        print(f\"Figure saved to {fig_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_seed_2_Training_2025-07-08_21-32-43.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_seed_2_Training_2025-07-08_21-34-21.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_seed_2_Training_2025-07-08_21-28-27.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_seed_2_Training_2025-07-08_21-26-10.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_seed_3_Training_2025-07-09_02-58-21.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_seed_3_Training_2025-07-09_03-04-42.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_seed_3_Training_2025-07-09_02-57-55.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_seed_3_Training_2025-07-09_02-56-48.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_seed_1_Training_2025-07-08_16-30-53.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_seed_1_Training_2025-07-08_16-31-09.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_seed_1_Training_2025-07-08_16-31-22.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_seed_1_Training_2025-07-08_16-26-49.png\n"
     ]
    }
   ],
   "source": [
    "# The five category columns\n",
    "categories = [\n",
    "    'own_coin_collected',\n",
    "    'other_coin_collected',\n",
    "    'reject_own_coin',\n",
    "    'reject_other_coin',\n",
    "    'no_coin_visible'\n",
    "]\n",
    "\n",
    "for seed, dir_info_list in seed_to_dirs.items():\n",
    "    for dir_path, coef, config_dict in dir_info_list:\n",
    "        csv_agent_0 = os.path.join(dir_path, f'policy_agent_0_checkpoint_{CHECKPOINT}.csv')\n",
    "        csv_agent_1 = os.path.join(dir_path, f'policy_agent_1_checkpoint_{CHECKPOINT}.csv')\n",
    "\n",
    "        if not (os.path.exists(csv_agent_0) and os.path.exists(csv_agent_1)):\n",
    "            print(f\"CSV files not found for SEED={seed} in {dir_path}\")\n",
    "            continue\n",
    "\n",
    "        df0 = pd.read_csv(csv_agent_0)\n",
    "        df1 = pd.read_csv(csv_agent_1)\n",
    "\n",
    "        # Count occurrences for each category\n",
    "        counts0 = [df0[cat].sum() for cat in categories_5]\n",
    "        counts1 = [df1[cat].sum() for cat in categories_5]\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        # Compose important info for the title\n",
    "        lr = config_dict.get('LR', 'N/A')\n",
    "        reward_coef = config_dict.get('REWARD_COEF', 'N/A')\n",
    "        title = (f\"Policy Category Counts for SEED={seed}\\n\"\n",
    "                 f\"LR={lr}, REWARD_COEF={reward_coef}\\n\"\n",
    "                 f\"Dir: {os.path.basename(dir_path)}\")\n",
    "        plt.suptitle(title, fontsize=14)\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.bar(categories_5, counts0, color='blue')\n",
    "        plt.title('Agent 0 Policy Categories')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=20)\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.bar(categories_5, counts1, color='red')\n",
    "        plt.title('Agent 1 Policy Categories')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=20)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.08, 1, 0.95])\n",
    "\n",
    "        # Save with seed and dir name in filename\n",
    "        safe_dir = os.path.basename(dir_path).replace(' ', '_')\n",
    "        fig_path = os.path.join(figures_dir, f'policy_categories_seed_{seed}_{safe_dir}.png')\n",
    "        plt.savefig(fig_path)\n",
    "        plt.close()\n",
    "        print(f\"Figure saved to {fig_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_globalmax_seed_2_Training_2025-07-08_21-32-43.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_globalmax_seed_2_Training_2025-07-08_21-34-21.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_globalmax_seed_2_Training_2025-07-08_21-28-27.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_globalmax_seed_2_Training_2025-07-08_21-26-10.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_globalmax_seed_3_Training_2025-07-09_02-58-21.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_globalmax_seed_3_Training_2025-07-09_03-04-42.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_globalmax_seed_3_Training_2025-07-09_02-57-55.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_globalmax_seed_3_Training_2025-07-09_02-56-48.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_globalmax_seed_1_Training_2025-07-08_16-30-53.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_globalmax_seed_1_Training_2025-07-08_16-31-09.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_globalmax_seed_1_Training_2025-07-08_16-31-22.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/policy_categories_globalmax_seed_1_Training_2025-07-08_16-26-49.png\n"
     ]
    }
   ],
   "source": [
    "# First pass: find the global maximum count\n",
    "global_max = 0\n",
    "\n",
    "for seed, dir_info_list in seed_to_dirs.items():\n",
    "    for dir_path, coef, config_dict in dir_info_list:\n",
    "        csv_agent_0 = os.path.join(dir_path, f'policy_agent_0_checkpoint_{CHECKPOINT}.csv')\n",
    "        csv_agent_1 = os.path.join(dir_path, f'policy_agent_1_checkpoint_{CHECKPOINT}.csv')\n",
    "\n",
    "        if not (os.path.exists(csv_agent_0) and os.path.exists(csv_agent_1)):\n",
    "            continue\n",
    "\n",
    "        df0 = pd.read_csv(csv_agent_0)\n",
    "        df1 = pd.read_csv(csv_agent_1)\n",
    "        counts0 = [df0[cat].sum() for cat in categories_2]\n",
    "        counts1 = [df1[cat].sum() for cat in categories_2]\n",
    "        local_max = max(counts0 + counts1)\n",
    "        if local_max > global_max:\n",
    "            global_max = local_max\n",
    "\n",
    "# Second pass: plot with the same ylim and save figures\n",
    "for seed, dir_info_list in seed_to_dirs.items():\n",
    "    for dir_path, coef, config_dict in dir_info_list:\n",
    "        csv_agent_0 = os.path.join(dir_path, f'policy_agent_0_checkpoint_{CHECKPOINT}.csv')\n",
    "        csv_agent_1 = os.path.join(dir_path, f'policy_agent_1_checkpoint_{CHECKPOINT}.csv')\n",
    "\n",
    "        if not (os.path.exists(csv_agent_0) and os.path.exists(csv_agent_1)):\n",
    "            print(f\"CSV files not found for SEED={seed} in {dir_path}\")\n",
    "            continue\n",
    "\n",
    "        df0 = pd.read_csv(csv_agent_0)\n",
    "        df1 = pd.read_csv(csv_agent_1)\n",
    "        counts0 = [df0[cat].sum() for cat in categories_2]\n",
    "        counts1 = [df1[cat].sum() for cat in categories_2]\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        # Compose important info for the title\n",
    "        lr = config_dict.get('LR', 'N/A')\n",
    "        reward_coef = config_dict.get('REWARD_COEF', 'N/A')\n",
    "        title = (f\"Policy Category Counts for SEED={seed}\\n\"\n",
    "                 f\"LR={lr}, REWARD_COEF={reward_coef}\\n\"\n",
    "                 f\"Dir: {os.path.basename(dir_path)}\")\n",
    "        plt.suptitle(title, fontsize=14)\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.bar(categories_2, counts0, color='blue')\n",
    "        plt.title('Agent 0 Policy Categories')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=20)\n",
    "        plt.ylim(0, global_max * 1.05)\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.bar(categories_2, counts1, color='red')\n",
    "        plt.title('Agent 1 Policy Categories')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=20)\n",
    "        plt.ylim(0, global_max * 1.05)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.08, 1, 0.95])\n",
    "\n",
    "        # Save with seed and dir name in filename\n",
    "        safe_dir = os.path.basename(dir_path).replace(' ', '_')\n",
    "        fig_path = os.path.join(figures_dir, f'policy_categories_globalmax_seed_{seed}_{safe_dir}.png')\n",
    "        plt.savefig(fig_path)\n",
    "        plt.close()\n",
    "        print(f\"Figure saved to {fig_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging over seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaging_dir = os.path.join(figures_dir, \"averaging_over_seeds\")\n",
    "os.makedirs(averaging_dir, exist_ok=True)\n",
    "\n",
    "df_all = pd.read_csv(os.path.join(MAIN_PATH, \"all_policies_combined.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find global max for 2-category bar\n",
    "global_max_2cat = 0\n",
    "for own_name, other_name in REWARD_ATTITUDE_PAIRS:\n",
    "    own_coef = attitudes[own_name]\n",
    "    other_coef = attitudes[other_name]\n",
    "    for agent_id in [0, 1]:\n",
    "        mask = df_all.apply(lambda row: match_coef(row, own_coef) and match_other_coef(row, other_coef) and row['AGENT_ID'] == agent_id, axis=1)\n",
    "        df = df_all[mask]\n",
    "        if not df.empty:\n",
    "            counts = [df[cat].sum() for cat in categories_2]\n",
    "            local_max = max(counts)\n",
    "            if local_max > global_max_2cat:\n",
    "                global_max_2cat = local_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/action_histogram_cooperative_as_agent0_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_5cat_cooperative_as_agent0_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_2cat_globalmax_cooperative_as_agent0_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/action_histogram_cooperative_as_agent1_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_5cat_cooperative_as_agent1_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_2cat_globalmax_cooperative_as_agent1_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/action_histogram_competitive_as_agent0_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_5cat_competitive_as_agent0_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_2cat_globalmax_competitive_as_agent0_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/action_histogram_competitive_as_agent1_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_5cat_competitive_as_agent1_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_2cat_globalmax_competitive_as_agent1_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/action_histogram_individualistic_as_agent0_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_5cat_individualistic_as_agent0_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_2cat_globalmax_individualistic_as_agent0_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/action_histogram_individualistic_as_agent1_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_5cat_individualistic_as_agent1_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_2cat_globalmax_individualistic_as_agent1_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/action_histogram_individualistic_as_agent0_vs_competitive.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_5cat_individualistic_as_agent0_vs_competitive.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_2cat_globalmax_individualistic_as_agent0_vs_competitive.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/action_histogram_individualistic_as_agent1_vs_competitive.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_5cat_individualistic_as_agent1_vs_competitive.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_2cat_globalmax_individualistic_as_agent1_vs_competitive.png\n"
     ]
    }
   ],
   "source": [
    "# Now plot for each (own, other, agent_id) triple\n",
    "for own_name, other_name in REWARD_ATTITUDE_PAIRS:\n",
    "    own_coef = attitudes[own_name]\n",
    "    other_coef = attitudes[other_name]\n",
    "    for agent_id in [0, 1]:\n",
    "        mask = df_all.apply(lambda row: match_coef(row, own_coef) and match_other_coef(row, other_coef) and row['AGENT_ID'] == agent_id, axis=1)\n",
    "        df = df_all[mask]\n",
    "        if df.empty:\n",
    "            print(f\"No data for {own_name} (as agent_{agent_id}) vs {other_name}\")\n",
    "            continue\n",
    "\n",
    "        # Action histogram\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.hist(df['action'].dropna(), bins=range(6), align='left', rwidth=0.8, color='gray')\n",
    "        ax.set_title(f'Action Histogram\\n{own_name.capitalize()} (as agent_{agent_id}) vs {other_name.capitalize()}')\n",
    "        ax.set_xlabel('Action')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_xticks(range(5))\n",
    "        ax.set_xticklabels(action_labels)\n",
    "        fname = f'action_histogram_{own_name}_as_agent{agent_id}_vs_{other_name}.png'\n",
    "        save_plot(fig, fname, averaging_dir)\n",
    "\n",
    "        # 5-category bar\n",
    "        avg_counts_5 = [df[cat].sum() for cat in categories_5]\n",
    "        x5 = np.arange(len(categories_5))\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.bar(x5, avg_counts_5, color='purple')\n",
    "        ax.set_title(f'5-Category Policy Bar\\n{own_name.capitalize()} (as agent_{agent_id}) vs {other_name.capitalize()}')\n",
    "        ax.set_ylabel('Average Count')\n",
    "        ax.set_xticks(x5)\n",
    "        ax.set_xticklabels(categories_5, rotation=20)\n",
    "        fname = f'policy_5cat_{own_name}_as_agent{agent_id}_vs_{other_name}.png'\n",
    "        save_plot(fig, fname, averaging_dir)\n",
    "\n",
    "        # 2-category bar (global max)\n",
    "        avg_counts_2 = [df[cat].sum() for cat in categories_2]\n",
    "        x2 = np.arange(len(categories_2))\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.bar(x2, avg_counts_2, color=['blue', 'red'])\n",
    "        ax.set_title(f'2-Category Policy Bar (Global Max)\\n{own_name.capitalize()} (as agent_{agent_id}) vs {other_name.capitalize()}')\n",
    "        ax.set_ylabel('Average Count')\n",
    "        ax.set_ylim(0, global_max_2cat * 1.05)\n",
    "        ax.set_xticks(x2)\n",
    "        ax.set_xticklabels(categories_2, rotation=20)\n",
    "        fname = f'policy_2cat_globalmax_{own_name}_as_agent{agent_id}_vs_{other_name}.png'\n",
    "        save_plot(fig, fname, averaging_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find global max for 2-category bar\n",
    "global_max_2cat_averaged = 0\n",
    "for own_name, own_coef in REWARD_ATTITUDE_PAIRS:\n",
    "    own_coef = attitudes[own_name]\n",
    "    other_coef = attitudes[other_name]\n",
    "    mask = df_all.apply(lambda row: match_coef(row, own_coef) and match_other_coef(row, other_coef), axis=1)\n",
    "    df = df_all[mask]\n",
    "    if not df.empty:\n",
    "        counts = [df[cat].sum() for cat in categories_2]\n",
    "        local_max = max(counts)\n",
    "        if local_max > global_max_2cat_averaged:\n",
    "            global_max_2cat_averaged = local_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/action_histogram_cooperative_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_5cat_cooperative_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_2cat_globalmax_cooperative_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/action_histogram_competitive_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_5cat_competitive_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_2cat_globalmax_competitive_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/action_histogram_individualistic_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_5cat_individualistic_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_2cat_globalmax_individualistic_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/action_histogram_individualistic_vs_competitive.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_5cat_individualistic_vs_competitive.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/policy_2cat_globalmax_individualistic_vs_competitive.png\n"
     ]
    }
   ],
   "source": [
    "# Now plot for each (own, other) pair\n",
    "for own_name, other_name in REWARD_ATTITUDE_PAIRS:\n",
    "    own_coef = attitudes[own_name]\n",
    "    other_coef = attitudes[other_name]\n",
    "    mask = df_all.apply(lambda row: match_coef(row, own_coef) and match_other_coef(row, other_coef), axis=1)\n",
    "    df = df_all[mask]\n",
    "    if df.empty:\n",
    "        print(f\"No data for {own_name} vs {other_name}\")\n",
    "        continue\n",
    "\n",
    "    # Action histogram\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.hist(df['action'].dropna(), bins=range(6), align='left', rwidth=0.8, color='gray')\n",
    "    ax.set_title(f'Action Histogram\\n{own_name.capitalize()} acting vs {other_name.capitalize()}')\n",
    "    ax.set_xlabel('Action')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_xticks(range(5))\n",
    "    ax.set_xticklabels(action_labels)\n",
    "    fname = f'action_histogram_{own_name}_vs_{other_name}.png'\n",
    "    save_plot(fig, fname, averaging_dir)\n",
    "\n",
    "    # 5-category bar\n",
    "    avg_counts_5 = [df[cat].sum() for cat in categories_5]\n",
    "    x5 = np.arange(len(categories_5))\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.bar(x5, avg_counts_5, color='purple')\n",
    "    ax.set_title(f'5-Category Policy Bar\\n{own_name.capitalize()} acting vs {other_name.capitalize()}')\n",
    "    ax.set_ylabel('Average Count')\n",
    "    ax.set_xticks(x5)\n",
    "    ax.set_xticklabels(categories_5, rotation=20)\n",
    "    fname = f'policy_5cat_{own_name}_vs_{other_name}.png'\n",
    "    save_plot(fig, fname, averaging_dir)\n",
    "\n",
    "    # 2-category bar (global max)\n",
    "    avg_counts_2 = [df[cat].sum() for cat in categories_2]\n",
    "    x2 = np.arange(len(categories_2))\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.bar(x2, avg_counts_2, color=['blue', 'red'])\n",
    "    ax.set_title(f'2-Category Policy Bar (Global Max)\\n{own_name.capitalize()} acting vs {other_name.capitalize()}')\n",
    "    ax.set_ylabel('Average Count')\n",
    "    ax.set_ylim(0, global_max_2cat_averaged * 1.05)\n",
    "    ax.set_xticks(x2)\n",
    "    ax.set_xticklabels(categories_2, rotation=20)\n",
    "    fname = f'policy_2cat_globalmax_{own_name}_vs_{other_name}.png'\n",
    "    save_plot(fig, fname, averaging_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_5cat_cooperative_as_agent0_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_2cat_globalmax_cooperative_as_agent0_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_5cat_cooperative_as_agent1_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_2cat_globalmax_cooperative_as_agent1_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_5cat_competitive_as_agent0_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_2cat_globalmax_competitive_as_agent0_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_5cat_competitive_as_agent1_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_2cat_globalmax_competitive_as_agent1_vs_individualistic.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_5cat_individualistic_as_agent0_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_2cat_globalmax_individualistic_as_agent0_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_5cat_individualistic_as_agent1_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_2cat_globalmax_individualistic_as_agent1_vs_cooperative.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_5cat_individualistic_as_agent0_vs_competitive.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_2cat_globalmax_individualistic_as_agent0_vs_competitive.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_5cat_individualistic_as_agent1_vs_competitive.png\n",
      "Figure saved to /home/samuel_lozano/data/samuel_lozano/CoopCoins/RLLIB/Individual/comparing_policies/averaging_over_seeds/mean_policy_2cat_globalmax_individualistic_as_agent1_vs_competitive.png\n"
     ]
    }
   ],
   "source": [
    "# Now plot for each (own, other, agent_id) triple\n",
    "for own_name, other_name in REWARD_ATTITUDE_PAIRS:\n",
    "    own_coef = attitudes[own_name]\n",
    "    other_coef = attitudes[other_name]\n",
    "    for agent_id in [0, 1]:\n",
    "        mask = df_all.apply(lambda row: match_coef(row, own_coef) and match_other_coef(row, other_coef) and row['AGENT_ID'] == agent_id, axis=1)\n",
    "        df = df_all[mask]\n",
    "        if df.empty:\n",
    "            print(f\"No data for {own_name} (as agent_{agent_id}) vs {other_name}\")\n",
    "            continue\n",
    "\n",
    "        # 5-category bar\n",
    "        avg_counts_5 = [df[cat].mean() for cat in categories_5]\n",
    "        x5 = np.arange(len(categories_5))\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.bar(x5, avg_counts_5, color='purple')\n",
    "        ax.set_title(f'5-Category Policy Bar\\n{own_name.capitalize()} (as agent_{agent_id}) vs {other_name.capitalize()}')\n",
    "        ax.set_ylabel('Average Count')\n",
    "        ax.set_xticks(x5)\n",
    "        ax.set_xticklabels(categories_5, rotation=20)\n",
    "        fname = f'mean_policy_5cat_{own_name}_as_agent{agent_id}_vs_{other_name}.png'\n",
    "        save_plot(fig, fname, averaging_dir)\n",
    "\n",
    "        # 2-category bar (global max)\n",
    "        avg_counts_2 = [df[cat].mean() for cat in categories_2]\n",
    "        x2 = np.arange(len(categories_2))\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.bar(x2, avg_counts_2, color=['blue', 'red'])\n",
    "        ax.set_title(f'2-Category Policy Bar (Global Max)\\n{own_name.capitalize()} (as agent_{agent_id}) vs {other_name.capitalize()}')\n",
    "        ax.set_ylabel('Average Count')\n",
    "        ax.set_xticks(x2)\n",
    "        ax.set_xticklabels(categories_2, rotation=20)\n",
    "        fname = f'mean_policy_2cat_globalmax_{own_name}_as_agent{agent_id}_vs_{other_name}.png'\n",
    "        save_plot(fig, fname, averaging_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaxMARL_TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
